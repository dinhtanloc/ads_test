{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbdd19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ef7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_dir = \"../../exps\"\n",
    "if os.path.exists(exps_dir) == False: # tạo thư mục (nếu chưa có)\n",
    "  os.makedirs(exps_dir, exist_ok=True)\n",
    "\n",
    "save_dir = f\"{exps_dir}/feature1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0baacb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_sex</th>\n",
       "      <th>insured_education_level</th>\n",
       "      <th>insured_occupation</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>day_policy_bind_date</th>\n",
       "      <th>month_policy_bind_date</th>\n",
       "      <th>year_policy_bind_date</th>\n",
       "      <th>day_incident_date</th>\n",
       "      <th>month_incident_date</th>\n",
       "      <th>year_incident_date</th>\n",
       "      <th>week_incident_date</th>\n",
       "      <th>high_week</th>\n",
       "      <th>high_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.770734</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.579574</td>\n",
       "      <td>-0.179439</td>\n",
       "      <td>-1.020460</td>\n",
       "      <td>-1.393943</td>\n",
       "      <td>-0.947412</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.705084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.979562</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.547936</td>\n",
       "      <td>-0.179439</td>\n",
       "      <td>0.908584</td>\n",
       "      <td>0.115223</td>\n",
       "      <td>0.953085</td>\n",
       "      <td>0</td>\n",
       "      <td>1.136723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.675544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.481582</td>\n",
       "      <td>0.108179</td>\n",
       "      <td>-0.744883</td>\n",
       "      <td>0.115223</td>\n",
       "      <td>-0.947412</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.893139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.492901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.368831</td>\n",
       "      <td>-0.467057</td>\n",
       "      <td>1.735317</td>\n",
       "      <td>-1.626123</td>\n",
       "      <td>2.853582</td>\n",
       "      <td>0</td>\n",
       "      <td>1.542695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.128570</td>\n",
       "      <td>0.971032</td>\n",
       "      <td>1.735317</td>\n",
       "      <td>1.160031</td>\n",
       "      <td>-0.947412</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.487167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.393488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.908354</td>\n",
       "      <td>0.656524</td>\n",
       "      <td>0.393463</td>\n",
       "      <td>-0.917630</td>\n",
       "      <td>-0.947412</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.409131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.839585</td>\n",
       "      <td>-0.592273</td>\n",
       "      <td>1.479683</td>\n",
       "      <td>0.680663</td>\n",
       "      <td>0.953085</td>\n",
       "      <td>0</td>\n",
       "      <td>1.071228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.077354</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.883912</td>\n",
       "      <td>-0.196871</td>\n",
       "      <td>-1.006542</td>\n",
       "      <td>-0.093503</td>\n",
       "      <td>0.914690</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706145</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.839075</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355841</td>\n",
       "      <td>-0.752419</td>\n",
       "      <td>0.704873</td>\n",
       "      <td>0.118865</td>\n",
       "      <td>0.953085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.070194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917317</td>\n",
       "      <td>-0.750775</td>\n",
       "      <td>1.459428</td>\n",
       "      <td>-0.233308</td>\n",
       "      <td>-0.947412</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.893139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      months_as_customer  age  policy_state  policy_csl  policy_deductable  \\\n",
       "0                      2    0             0           1                  1   \n",
       "1                      0    2             1           0                  2   \n",
       "2                      2    0             2           0                  2   \n",
       "3                      2    0             0           0                  2   \n",
       "4                      2    0             2           1                  1   \n",
       "...                  ...  ...           ...         ...                ...   \n",
       "1017                   2    0             2           0                  2   \n",
       "1018                   1    0             0           0                  0   \n",
       "1019                   0    0             1           0                  1   \n",
       "1020                   0    0             1           0                  0   \n",
       "1021                   1    0             0           1                  0   \n",
       "\n",
       "      policy_annual_premium  umbrella_limit  insured_sex  \\\n",
       "0                 -1.770734               0            1   \n",
       "1                 -1.979562               0            1   \n",
       "2                  0.675544               0            0   \n",
       "3                 -0.492901               0            0   \n",
       "4                  0.613672               0            1   \n",
       "...                     ...             ...          ...   \n",
       "1017              -1.393488               0            0   \n",
       "1018               0.661055               0            0   \n",
       "1019              -0.077354               5            1   \n",
       "1020              -0.839075               3            0   \n",
       "1021              -0.070194               0            1   \n",
       "\n",
       "      insured_education_level  insured_occupation  ...  auto_year  \\\n",
       "0                           2                  11  ...          2   \n",
       "1                           4                  11  ...          0   \n",
       "2                           0                   5  ...          1   \n",
       "3                           2                   2  ...          0   \n",
       "4                           4                   2  ...          1   \n",
       "...                       ...                 ...  ...        ...   \n",
       "1017                        0                   6  ...          1   \n",
       "1018                        1                   3  ...          0   \n",
       "1019                        4                   3  ...          1   \n",
       "1020                        5                   5  ...          1   \n",
       "1021                        3                   3  ...          0   \n",
       "\n",
       "      day_policy_bind_date  month_policy_bind_date  year_policy_bind_date  \\\n",
       "0                 0.579574               -0.179439              -1.020460   \n",
       "1                -0.547936               -0.179439               0.908584   \n",
       "2                 1.481582                0.108179              -0.744883   \n",
       "3                 1.368831               -0.467057               1.735317   \n",
       "4                 0.128570                0.971032               1.735317   \n",
       "...                    ...                     ...                    ...   \n",
       "1017              0.908354                0.656524               0.393463   \n",
       "1018              0.839585               -0.592273               1.479683   \n",
       "1019             -0.883912               -0.196871              -1.006542   \n",
       "1020              0.355841               -0.752419               0.704873   \n",
       "1021              0.917317               -0.750775               1.459428   \n",
       "\n",
       "      day_incident_date  month_incident_date  year_incident_date  \\\n",
       "0             -1.393943            -0.947412                   0   \n",
       "1              0.115223             0.953085                   0   \n",
       "2              0.115223            -0.947412                   0   \n",
       "3             -1.626123             2.853582                   0   \n",
       "4              1.160031            -0.947412                   0   \n",
       "...                 ...                  ...                 ...   \n",
       "1017          -0.917630            -0.947412                   0   \n",
       "1018           0.680663             0.953085                   0   \n",
       "1019          -0.093503             0.914690                   0   \n",
       "1020           0.118865             0.953085                   0   \n",
       "1021          -0.233308            -0.947412                   0   \n",
       "\n",
       "      week_incident_date  high_week  high_hour  \n",
       "0              -1.705084          0          0  \n",
       "1               1.136723          0          0  \n",
       "2              -0.893139          1          0  \n",
       "3               1.542695          0          0  \n",
       "4              -0.487167          1          0  \n",
       "...                  ...        ...        ...  \n",
       "1017           -1.409131          0          0  \n",
       "1018            1.071228          0          0  \n",
       "1019            0.706145          1          1  \n",
       "1020            0.936124          0          0  \n",
       "1021           -0.893139          1          0  \n",
       "\n",
       "[1022 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a905f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 42, 1)\n",
      "(None, 1, 1024)\n",
      "(None, 1, 1)\n",
      "Model: \"mobilenet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 42, 1)]           0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 21, 32)            96        \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 21, 32)           84        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (Activation)     (None, 21, 32)            0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv1D)  (None, 21, 32)           96        \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 21, 32)           84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (Activation)  (None, 21, 32)           0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv1D)          (None, 21, 64)            2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 21, 64)           84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (Activation)  (None, 21, 64)           0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv1D)  (None, 21, 64)           192       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 21, 64)           84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (Activation)  (None, 21, 64)           0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv1D)          (None, 21, 128)           8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 21, 128)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (Activation)  (None, 21, 128)          0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv1D)  (None, 21, 128)          384       \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 21, 128)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (Activation)  (None, 21, 128)          0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv1D)          (None, 21, 128)           16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 21, 128)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (Activation)  (None, 21, 128)          0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv1D)  (None, 21, 128)          384       \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 21, 128)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (Activation)  (None, 21, 128)          0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv1D)          (None, 21, 256)           32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 21, 256)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (Activation)  (None, 21, 256)          0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv1D)  (None, 21, 256)          768       \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 21, 256)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (Activation)  (None, 21, 256)          0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv1D)          (None, 21, 256)           65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 21, 256)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (Activation)  (None, 21, 256)          0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv1D)  (None, 21, 256)          768       \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 21, 256)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (Activation)  (None, 21, 256)          0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv1D)          (None, 21, 512)           131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv1D)  (None, 21, 512)          1536      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv1D)          (None, 21, 512)           262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv1D)  (None, 21, 512)          1536      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv1D)          (None, 21, 512)           262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv_dw_9 (DepthwiseConv1D)  (None, 21, 512)          1536      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv1D)          (None, 21, 512)           262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 21, 512)          84        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (Activation)  (None, 21, 512)          0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv1D  (None, 21, 512)          1536      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 21, 512)          84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (Activation  (None, 21, 512)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_pw_10 (Conv1D)         (None, 21, 512)           262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 21, 512)          84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (Activation  (None, 21, 512)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv1D  (None, 21, 512)          1536      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 21, 512)          84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (Activation  (None, 21, 512)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_pw_11 (Conv1D)         (None, 21, 512)           262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 21, 512)          84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (Activation  (None, 21, 512)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv1D  (None, 21, 512)          1536      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 21, 512)          84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (Activation  (None, 21, 512)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_pw_12 (Conv1D)         (None, 21, 1024)          524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 21, 1024)         84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (Activation  (None, 21, 1024)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv1D  (None, 21, 1024)         3072      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 21, 1024)         84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (Activation  (None, 21, 1024)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_pw_13 (Conv1D)         (None, 21, 1024)          1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 21, 1024)         84        \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (Activation  (None, 21, 1024)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 1024)             0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 1024)           0         \n",
      "                                                                 \n",
      " conv_preds (Conv1D)         (None, 1, 1)              1025      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 1, 1)              0         \n",
      "                                                                 \n",
      " act_softmax (Activation)    (None, 1, 1)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,157,853\n",
      "Trainable params: 3,156,719\n",
      "Non-trainable params: 1,134\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, Reshape, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class DepthwiseConv1D(Layer):\n",
    "    def __init__(self, kernel_size, depth_multiplier=1, strides=1, padding='valid', **kwargs):\n",
    "        super(DepthwiseConv1D, self).__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.depth_multiplier = depth_multiplier\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 3:\n",
    "            raise ValueError('Input shape should be a tuple of 3 dimensions.')\n",
    "        input_dim = input_shape[2]\n",
    "        depthwise_kernel_shape = (self.kernel_size, input_dim, self.depth_multiplier)\n",
    "\n",
    "        self.depthwise_kernel = self.add_weight(shape=depthwise_kernel_shape,\n",
    "                                                initializer='glorot_uniform',\n",
    "                                                name='depthwise_kernel')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        length = input_shape[1]\n",
    "        if self.padding == 'valid':\n",
    "            length -= self.kernel_size - 1\n",
    "        length = (length + self.strides - 1) // self.strides\n",
    "\n",
    "        return (input_shape[0], length, input_shape[2] * self.depth_multiplier)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n",
    "\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2.\n",
    "    return x\n",
    "\n",
    "def MobileNet(input_shape=None, alpha=1.0, depth_multiplier=1, dropout=1e-3, classes=1):\n",
    "    input_shape = (42,1)\n",
    "    x_input = Input(shape=input_shape)\n",
    "    print(x_input.shape)\n",
    "    x = _conv_block(x_input, 32, alpha, strides=2)\n",
    "    x = _depthwise_conv_block(x, 64, alpha, depth_multiplier, block_id=1)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, strides=2, block_id=2)\n",
    "    x = _depthwise_conv_block(x, 128, alpha, depth_multiplier, block_id=3)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, strides=2, block_id=4)\n",
    "    x = _depthwise_conv_block(x, 256, alpha, depth_multiplier, block_id=5)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, strides=2, block_id=6)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=7)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=8)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=9)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=10)\n",
    "    x = _depthwise_conv_block(x, 512, alpha, depth_multiplier, block_id=11)\n",
    "\n",
    "    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, strides=2, block_id=12)\n",
    "    x = _depthwise_conv_block(x, 1024, alpha, depth_multiplier, block_id=13)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(dropout, name='dropout')(x)\n",
    "    x = Reshape((1, 1024))(x)\n",
    "    print(x.shape)\n",
    "    x = Conv1D(classes, 1, padding='same', name='conv_preds')(x)\n",
    "    print(x.shape)\n",
    "    x = Reshape((1,1), name='reshape_2')(x)\n",
    "    x = Activation('sigmoid', name='act_softmax')(x)\n",
    "    model = Model(inputs=x_input, outputs=x, name='mobilenet')\n",
    "    return model\n",
    "\n",
    "def _conv_block(inputs, filters, alpha, kernel=3, strides=1):\n",
    "    channel_axis = 1\n",
    "    filters = int(filters * alpha)\n",
    "    x = Conv1D(filters, kernel,\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               strides=strides,\n",
    "               name='conv1')(inputs)\n",
    "    x = BatchNormalization(axis=channel_axis, name='conv1_bn')(x)\n",
    "    return Activation('relu', name='conv1_relu')(x)\n",
    "\n",
    "def _depthwise_conv_block(inputs, pointwise_conv_filters, alpha,\n",
    "                          depth_multiplier=1, strides=1, block_id=1):\n",
    "    channel_axis = 1\n",
    "    pointwise_conv_filters = int(pointwise_conv_filters * alpha)\n",
    "\n",
    "    x = DepthwiseConv1D(3,\n",
    "                        padding='same',\n",
    "                        depth_multiplier=depth_multiplier,\n",
    "                        strides=strides,\n",
    "                        name='conv_dw_%d' % block_id)(inputs)\n",
    "    x = BatchNormalization(axis=channel_axis, name='conv_dw_%d_bn' % block_id)(x)\n",
    "    x = Activation(relu6, name='conv_dw_%d_relu' % block_id)(x)\n",
    "\n",
    "    x = Conv1D(pointwise_conv_filters, 1,\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               strides=1,\n",
    "               name='conv_pw_%d' % block_id)(x)\n",
    "    x = BatchNormalization(axis=channel_axis, name='conv_pw_%d_bn' % block_id)(x)\n",
    "    return Activation('relu', name='conv_pw_%d_relu' % block_id)(x)\n",
    "\n",
    "model = MobileNet()\n",
    "lr=0.0001\n",
    "model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b24d441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv_dw_1/depthwise_kernel:0', 'conv_dw_2/depthwise_kernel:0', 'conv_dw_3/depthwise_kernel:0', 'conv_dw_4/depthwise_kernel:0', 'conv_dw_5/depthwise_kernel:0', 'conv_dw_6/depthwise_kernel:0', 'conv_dw_7/depthwise_kernel:0', 'conv_dw_8/depthwise_kernel:0', 'conv_dw_9/depthwise_kernel:0', 'conv_dw_10/depthwise_kernel:0', 'conv_dw_11/depthwise_kernel:0', 'conv_dw_12/depthwise_kernel:0', 'conv_dw_13/depthwise_kernel:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv_dw_1/depthwise_kernel:0', 'conv_dw_2/depthwise_kernel:0', 'conv_dw_3/depthwise_kernel:0', 'conv_dw_4/depthwise_kernel:0', 'conv_dw_5/depthwise_kernel:0', 'conv_dw_6/depthwise_kernel:0', 'conv_dw_7/depthwise_kernel:0', 'conv_dw_8/depthwise_kernel:0', 'conv_dw_9/depthwise_kernel:0', 'conv_dw_10/depthwise_kernel:0', 'conv_dw_11/depthwise_kernel:0', 'conv_dw_12/depthwise_kernel:0', 'conv_dw_13/depthwise_kernel:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "11/11 [==============================] - 1s 15ms/stepss: 0.7031 - accuracy: \n",
      "Confusion Matrix after Epoch 1:\n",
      "[[242   0]\n",
      " [ 88   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85       242\n",
      "           1       0.00      0.00      0.00        88\n",
      "\n",
      "    accuracy                           0.73       330\n",
      "   macro avg       0.37      0.50      0.42       330\n",
      "weighted avg       0.54      0.73      0.62       330\n",
      "\n",
      "16/16 [==============================] - 12s 419ms/step - loss: 0.7031 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.7333\n",
      "Epoch 2/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/stepss: 0.6501 - accuracy: \n",
      "Confusion Matrix after Epoch 2:\n",
      "[[  0 242]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.13      0.50      0.21       330\n",
      "weighted avg       0.07      0.27      0.11       330\n",
      "\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 0.6501 - accuracy: 0.6321 - val_loss: 0.6936 - val_accuracy: 0.2667\n",
      "Epoch 3/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/stepss: 0.6267 - accuracy: \n",
      "Confusion Matrix after Epoch 3:\n",
      "[[  0 242]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.13      0.50      0.21       330\n",
      "weighted avg       0.07      0.27      0.11       330\n",
      "\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.6267 - accuracy: 0.6673 - val_loss: 0.6938 - val_accuracy: 0.2667\n",
      "Epoch 4/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/stepss: 0.6024 - accuracy: \n",
      "Confusion Matrix after Epoch 4:\n",
      "[[  0 242]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.13      0.50      0.21       330\n",
      "weighted avg       0.07      0.27      0.11       330\n",
      "\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 0.6024 - accuracy: 0.6888 - val_loss: 0.6941 - val_accuracy: 0.2667\n",
      "Epoch 5/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/stepss: 0.5898 - accuracy: \n",
      "Confusion Matrix after Epoch 5:\n",
      "[[  0 242]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.13      0.50      0.21       330\n",
      "weighted avg       0.07      0.27      0.11       330\n",
      "\n",
      "16/16 [==============================] - 4s 260ms/step - loss: 0.5898 - accuracy: 0.7143 - val_loss: 0.6943 - val_accuracy: 0.2667\n",
      "Epoch 6/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/stepss: 0.5774 - accuracy: \n",
      "Confusion Matrix after Epoch 6:\n",
      "[[  0 242]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.13      0.50      0.21       330\n",
      "weighted avg       0.07      0.27      0.11       330\n",
      "\n",
      "16/16 [==============================] - 4s 272ms/step - loss: 0.5774 - accuracy: 0.7084 - val_loss: 0.6945 - val_accuracy: 0.2667\n",
      "Epoch 7/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/stepss: 0.5542 - accuracy: \n",
      "Confusion Matrix after Epoch 7:\n",
      "[[  0 242]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.13      0.50      0.21       330\n",
      "weighted avg       0.07      0.27      0.11       330\n",
      "\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.5542 - accuracy: 0.7407 - val_loss: 0.6947 - val_accuracy: 0.2667\n",
      "Epoch 8/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/stepss: 0.5501 - accuracy: \n",
      "Confusion Matrix after Epoch 8:\n",
      "[[  0 242]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.13      0.50      0.21       330\n",
      "weighted avg       0.07      0.27      0.11       330\n",
      "\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.5501 - accuracy: 0.7417 - val_loss: 0.6950 - val_accuracy: 0.2667\n",
      "Epoch 9/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/stepss: 0.5690 - accuracy: \n",
      "Confusion Matrix after Epoch 9:\n",
      "[[  0 242]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.13      0.50      0.21       330\n",
      "weighted avg       0.07      0.27      0.11       330\n",
      "\n",
      "16/16 [==============================] - 4s 265ms/step - loss: 0.5690 - accuracy: 0.7221 - val_loss: 0.6956 - val_accuracy: 0.2667\n",
      "Epoch 10/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/stepss: 0.5268 - accuracy: \n",
      "Confusion Matrix after Epoch 10:\n",
      "[[  0 242]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.13      0.50      0.21       330\n",
      "weighted avg       0.07      0.27      0.11       330\n",
      "\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.5268 - accuracy: 0.7466 - val_loss: 0.6971 - val_accuracy: 0.2667\n",
      "Epoch 11/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/stepss: 0.5196 - accuracy: \n",
      "Confusion Matrix after Epoch 11:\n",
      "[[  1 241]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.01       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.63      0.50      0.22       330\n",
      "weighted avg       0.80      0.27      0.12       330\n",
      "\n",
      "16/16 [==============================] - 5s 294ms/step - loss: 0.5196 - accuracy: 0.7583 - val_loss: 0.6996 - val_accuracy: 0.2697\n",
      "Epoch 12/120\n",
      "11/11 [==============================] - 0s 18ms/stepss: 0.5162 - accuracy\n",
      "Confusion Matrix after Epoch 12:\n",
      "[[  1 241]\n",
      " [  0  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.01       242\n",
      "           1       0.27      1.00      0.42        88\n",
      "\n",
      "    accuracy                           0.27       330\n",
      "   macro avg       0.63      0.50      0.22       330\n",
      "weighted avg       0.80      0.27      0.12       330\n",
      "\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.5162 - accuracy: 0.7593 - val_loss: 0.7106 - val_accuracy: 0.2697\n",
      "Epoch 13/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.5433 - accuracy\n",
      "Confusion Matrix after Epoch 13:\n",
      "[[ 10 232]\n",
      " [  5  83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.04      0.08       242\n",
      "           1       0.26      0.94      0.41        88\n",
      "\n",
      "    accuracy                           0.28       330\n",
      "   macro avg       0.47      0.49      0.24       330\n",
      "weighted avg       0.56      0.28      0.17       330\n",
      "\n",
      "16/16 [==============================] - 5s 286ms/step - loss: 0.5433 - accuracy: 0.7407 - val_loss: 0.7170 - val_accuracy: 0.2818\n",
      "Epoch 14/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.4875 - accuracy: \n",
      "Confusion Matrix after Epoch 14:\n",
      "[[ 11 231]\n",
      " [  3  85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.05      0.09       242\n",
      "           1       0.27      0.97      0.42        88\n",
      "\n",
      "    accuracy                           0.29       330\n",
      "   macro avg       0.53      0.51      0.25       330\n",
      "weighted avg       0.65      0.29      0.18       330\n",
      "\n",
      "16/16 [==============================] - 5s 306ms/step - loss: 0.4875 - accuracy: 0.7759 - val_loss: 0.7342 - val_accuracy: 0.2909\n",
      "Epoch 15/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.4879 - accuracy: \n",
      "Confusion Matrix after Epoch 15:\n",
      "[[ 13 229]\n",
      " [  5  83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.05      0.10       242\n",
      "           1       0.27      0.94      0.41        88\n",
      "\n",
      "    accuracy                           0.29       330\n",
      "   macro avg       0.49      0.50      0.26       330\n",
      "weighted avg       0.60      0.29      0.18       330\n",
      "\n",
      "16/16 [==============================] - 5s 306ms/step - loss: 0.4879 - accuracy: 0.7583 - val_loss: 0.7625 - val_accuracy: 0.2909\n",
      "Epoch 16/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.4995 - accuracy: \n",
      "Confusion Matrix after Epoch 16:\n",
      "[[ 21 221]\n",
      " [  6  82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.09      0.16       242\n",
      "           1       0.27      0.93      0.42        88\n",
      "\n",
      "    accuracy                           0.31       330\n",
      "   macro avg       0.52      0.51      0.29       330\n",
      "weighted avg       0.64      0.31      0.23       330\n",
      "\n",
      "16/16 [==============================] - 5s 298ms/step - loss: 0.4995 - accuracy: 0.7603 - val_loss: 0.7725 - val_accuracy: 0.3121\n",
      "Epoch 17/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.4630 - accuracy: \n",
      "Confusion Matrix after Epoch 17:\n",
      "[[ 19 223]\n",
      " [  3  85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.08      0.14       242\n",
      "           1       0.28      0.97      0.43        88\n",
      "\n",
      "    accuracy                           0.32       330\n",
      "   macro avg       0.57      0.52      0.29       330\n",
      "weighted avg       0.71      0.32      0.22       330\n",
      "\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.4630 - accuracy: 0.8014 - val_loss: 0.8354 - val_accuracy: 0.3152\n",
      "Epoch 18/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.4426 - accuracy: \n",
      "Confusion Matrix after Epoch 18:\n",
      "[[  8 234]\n",
      " [  4  84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.06       242\n",
      "           1       0.26      0.95      0.41        88\n",
      "\n",
      "    accuracy                           0.28       330\n",
      "   macro avg       0.47      0.49      0.24       330\n",
      "weighted avg       0.56      0.28      0.16       330\n",
      "\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 0.4426 - accuracy: 0.7955 - val_loss: 0.9057 - val_accuracy: 0.2788\n",
      "Epoch 19/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.4763 - accuracy: \n",
      "Confusion Matrix after Epoch 19:\n",
      "[[ 37 205]\n",
      " [  9  79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.15      0.26       242\n",
      "           1       0.28      0.90      0.42        88\n",
      "\n",
      "    accuracy                           0.35       330\n",
      "   macro avg       0.54      0.53      0.34       330\n",
      "weighted avg       0.66      0.35      0.30       330\n",
      "\n",
      "16/16 [==============================] - 5s 294ms/step - loss: 0.4763 - accuracy: 0.7779 - val_loss: 0.8237 - val_accuracy: 0.3515\n",
      "Epoch 20/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.4495 - accuracy\n",
      "Confusion Matrix after Epoch 20:\n",
      "[[ 58 184]\n",
      " [ 18  70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.24      0.36       242\n",
      "           1       0.28      0.80      0.41        88\n",
      "\n",
      "    accuracy                           0.39       330\n",
      "   macro avg       0.52      0.52      0.39       330\n",
      "weighted avg       0.63      0.39      0.38       330\n",
      "\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.4495 - accuracy: 0.7886 - val_loss: 0.8828 - val_accuracy: 0.3879\n",
      "Epoch 21/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.4224 - accuracy: \n",
      "Confusion Matrix after Epoch 21:\n",
      "[[ 23 219]\n",
      " [  7  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.10      0.17       242\n",
      "           1       0.27      0.92      0.42        88\n",
      "\n",
      "    accuracy                           0.32       330\n",
      "   macro avg       0.52      0.51      0.29       330\n",
      "weighted avg       0.63      0.32      0.24       330\n",
      "\n",
      "16/16 [==============================] - 5s 295ms/step - loss: 0.4224 - accuracy: 0.8053 - val_loss: 1.1092 - val_accuracy: 0.3152\n",
      "Epoch 22/120\n",
      "11/11 [==============================] - 0s 14ms/stepss: 0.4309 - accuracy: \n",
      "Confusion Matrix after Epoch 22:\n",
      "[[ 55 187]\n",
      " [ 15  73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.23      0.35       242\n",
      "           1       0.28      0.83      0.42        88\n",
      "\n",
      "    accuracy                           0.39       330\n",
      "   macro avg       0.53      0.53      0.39       330\n",
      "weighted avg       0.65      0.39      0.37       330\n",
      "\n",
      "16/16 [==============================] - 5s 295ms/step - loss: 0.4309 - accuracy: 0.8141 - val_loss: 0.9858 - val_accuracy: 0.3879\n",
      "Epoch 23/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.4186 - accuracy: \n",
      "Confusion Matrix after Epoch 23:\n",
      "[[ 82 160]\n",
      " [ 31  57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.34      0.46       242\n",
      "           1       0.26      0.65      0.37        88\n",
      "\n",
      "    accuracy                           0.42       330\n",
      "   macro avg       0.49      0.49      0.42       330\n",
      "weighted avg       0.60      0.42      0.44       330\n",
      "\n",
      "16/16 [==============================] - 5s 298ms/step - loss: 0.4186 - accuracy: 0.8053 - val_loss: 0.9060 - val_accuracy: 0.4212\n",
      "Epoch 24/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.4439 - accuracy: \n",
      "Confusion Matrix after Epoch 24:\n",
      "[[115 127]\n",
      " [ 36  52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.48      0.59       242\n",
      "           1       0.29      0.59      0.39        88\n",
      "\n",
      "    accuracy                           0.51       330\n",
      "   macro avg       0.53      0.53      0.49       330\n",
      "weighted avg       0.64      0.51      0.53       330\n",
      "\n",
      "16/16 [==============================] - 5s 338ms/step - loss: 0.4439 - accuracy: 0.8053 - val_loss: 0.8068 - val_accuracy: 0.5061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.4324 - accuracy\n",
      "Confusion Matrix after Epoch 25:\n",
      "[[ 94 148]\n",
      " [ 24  64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.39      0.52       242\n",
      "           1       0.30      0.73      0.43        88\n",
      "\n",
      "    accuracy                           0.48       330\n",
      "   macro avg       0.55      0.56      0.47       330\n",
      "weighted avg       0.66      0.48      0.50       330\n",
      "\n",
      "16/16 [==============================] - 5s 320ms/step - loss: 0.4324 - accuracy: 0.8160 - val_loss: 0.8866 - val_accuracy: 0.4788\n",
      "Epoch 26/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.3939 - accuracy: \n",
      "Confusion Matrix after Epoch 26:\n",
      "[[104 138]\n",
      " [ 28  60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.43      0.56       242\n",
      "           1       0.30      0.68      0.42        88\n",
      "\n",
      "    accuracy                           0.50       330\n",
      "   macro avg       0.55      0.56      0.49       330\n",
      "weighted avg       0.66      0.50      0.52       330\n",
      "\n",
      "16/16 [==============================] - 5s 303ms/step - loss: 0.3939 - accuracy: 0.8337 - val_loss: 0.8545 - val_accuracy: 0.4970\n",
      "Epoch 27/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.3608 - accuracy\n",
      "Confusion Matrix after Epoch 27:\n",
      "[[106 136]\n",
      " [ 30  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.44      0.56       242\n",
      "           1       0.30      0.66      0.41        88\n",
      "\n",
      "    accuracy                           0.50       330\n",
      "   macro avg       0.54      0.55      0.49       330\n",
      "weighted avg       0.65      0.50      0.52       330\n",
      "\n",
      "16/16 [==============================] - 5s 306ms/step - loss: 0.3608 - accuracy: 0.8523 - val_loss: 0.9103 - val_accuracy: 0.4970\n",
      "Epoch 28/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.3664 - accuracy: \n",
      "Confusion Matrix after Epoch 28:\n",
      "[[128 114]\n",
      " [ 34  54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.53      0.63       242\n",
      "           1       0.32      0.61      0.42        88\n",
      "\n",
      "    accuracy                           0.55       330\n",
      "   macro avg       0.56      0.57      0.53       330\n",
      "weighted avg       0.67      0.55      0.58       330\n",
      "\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 0.3664 - accuracy: 0.8513 - val_loss: 0.8919 - val_accuracy: 0.5515\n",
      "Epoch 29/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.3888 - accuracy: \n",
      "Confusion Matrix after Epoch 29:\n",
      "[[135 107]\n",
      " [ 41  47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.56      0.65       242\n",
      "           1       0.31      0.53      0.39        88\n",
      "\n",
      "    accuracy                           0.55       330\n",
      "   macro avg       0.54      0.55      0.52       330\n",
      "weighted avg       0.64      0.55      0.58       330\n",
      "\n",
      "16/16 [==============================] - 4s 268ms/step - loss: 0.3888 - accuracy: 0.8190 - val_loss: 0.8233 - val_accuracy: 0.5515\n",
      "Epoch 30/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.3664 - accuracy: \n",
      "Confusion Matrix after Epoch 30:\n",
      "[[121 121]\n",
      " [ 30  58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62       242\n",
      "           1       0.32      0.66      0.43        88\n",
      "\n",
      "    accuracy                           0.54       330\n",
      "   macro avg       0.56      0.58      0.53       330\n",
      "weighted avg       0.67      0.54      0.57       330\n",
      "\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 0.3664 - accuracy: 0.8415 - val_loss: 0.9222 - val_accuracy: 0.5424\n",
      "Epoch 31/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.3500 - accuracy: \n",
      "Confusion Matrix after Epoch 31:\n",
      "[[164  78]\n",
      " [ 53  35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.71       242\n",
      "           1       0.31      0.40      0.35        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.53      0.54      0.53       330\n",
      "weighted avg       0.64      0.60      0.62       330\n",
      "\n",
      "16/16 [==============================] - 5s 332ms/step - loss: 0.3500 - accuracy: 0.8376 - val_loss: 0.7891 - val_accuracy: 0.6030\n",
      "Epoch 32/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.3826 - accuracy: \n",
      "Confusion Matrix after Epoch 32:\n",
      "[[136 106]\n",
      " [ 45  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64       242\n",
      "           1       0.29      0.49      0.36        88\n",
      "\n",
      "    accuracy                           0.54       330\n",
      "   macro avg       0.52      0.53      0.50       330\n",
      "weighted avg       0.63      0.54      0.57       330\n",
      "\n",
      "16/16 [==============================] - 5s 330ms/step - loss: 0.3826 - accuracy: 0.8258 - val_loss: 0.9066 - val_accuracy: 0.5424\n",
      "Epoch 33/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.3780 - accuracy\n",
      "Confusion Matrix after Epoch 33:\n",
      "[[ 90 152]\n",
      " [ 20  68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.37      0.51       242\n",
      "           1       0.31      0.77      0.44        88\n",
      "\n",
      "    accuracy                           0.48       330\n",
      "   macro avg       0.56      0.57      0.48       330\n",
      "weighted avg       0.68      0.48      0.49       330\n",
      "\n",
      "16/16 [==============================] - 5s 317ms/step - loss: 0.3780 - accuracy: 0.8297 - val_loss: 1.2251 - val_accuracy: 0.4788\n",
      "Epoch 34/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.3568 - accuracy: \n",
      "Confusion Matrix after Epoch 34:\n",
      "[[123 119]\n",
      " [ 40  48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.51      0.61       242\n",
      "           1       0.29      0.55      0.38        88\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.52      0.53      0.49       330\n",
      "weighted avg       0.63      0.52      0.55       330\n",
      "\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 0.3568 - accuracy: 0.8503 - val_loss: 0.9763 - val_accuracy: 0.5182\n",
      "Epoch 35/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.3148 - accuracy: \n",
      "Confusion Matrix after Epoch 35:\n",
      "[[182  60]\n",
      " [ 62  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       242\n",
      "           1       0.30      0.30      0.30        88\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.52      0.52      0.52       330\n",
      "weighted avg       0.63      0.63      0.63       330\n",
      "\n",
      "16/16 [==============================] - 5s 327ms/step - loss: 0.3148 - accuracy: 0.8787 - val_loss: 0.8157 - val_accuracy: 0.6303\n",
      "Epoch 36/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.3223 - accuracy\n",
      "Confusion Matrix after Epoch 36:\n",
      "[[161  81]\n",
      " [ 56  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70       242\n",
      "           1       0.28      0.36      0.32        88\n",
      "\n",
      "    accuracy                           0.58       330\n",
      "   macro avg       0.51      0.51      0.51       330\n",
      "weighted avg       0.62      0.58      0.60       330\n",
      "\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 0.3223 - accuracy: 0.8620 - val_loss: 0.8661 - val_accuracy: 0.5848\n",
      "Epoch 37/120\n",
      "11/11 [==============================] - 0s 18ms/stepss: 0.3255 - accuracy\n",
      "Confusion Matrix after Epoch 37:\n",
      "[[151  91]\n",
      " [ 49  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.68       242\n",
      "           1       0.30      0.44      0.36        88\n",
      "\n",
      "    accuracy                           0.58       330\n",
      "   macro avg       0.53      0.53      0.52       330\n",
      "weighted avg       0.63      0.58      0.60       330\n",
      "\n",
      "16/16 [==============================] - 5s 327ms/step - loss: 0.3255 - accuracy: 0.8728 - val_loss: 0.9243 - val_accuracy: 0.5758\n",
      "Epoch 38/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.3017 - accuracy: \n",
      "Confusion Matrix after Epoch 38:\n",
      "[[160  82]\n",
      " [ 48  40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.66      0.71       242\n",
      "           1       0.33      0.45      0.38        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.55      0.56      0.55       330\n",
      "weighted avg       0.65      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.3017 - accuracy: 0.8767 - val_loss: 0.8608 - val_accuracy: 0.6061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.2865 - accuracy: \n",
      "Confusion Matrix after Epoch 39:\n",
      "[[133 109]\n",
      " [ 45  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.55      0.63       242\n",
      "           1       0.28      0.49      0.36        88\n",
      "\n",
      "    accuracy                           0.53       330\n",
      "   macro avg       0.52      0.52      0.50       330\n",
      "weighted avg       0.62      0.53      0.56       330\n",
      "\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 0.2865 - accuracy: 0.8894 - val_loss: 1.0418 - val_accuracy: 0.5333\n",
      "Epoch 40/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.3101 - accuracy: \n",
      "Confusion Matrix after Epoch 40:\n",
      "[[110 132]\n",
      " [ 29  59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.45      0.58       242\n",
      "           1       0.31      0.67      0.42        88\n",
      "\n",
      "    accuracy                           0.51       330\n",
      "   macro avg       0.55      0.56      0.50       330\n",
      "weighted avg       0.66      0.51      0.54       330\n",
      "\n",
      "16/16 [==============================] - 5s 298ms/step - loss: 0.3101 - accuracy: 0.8542 - val_loss: 1.0872 - val_accuracy: 0.5121\n",
      "Epoch 41/120\n",
      "11/11 [==============================] - 0s 18ms/stepss: 0.2955 - accuracy\n",
      "Confusion Matrix after Epoch 41:\n",
      "[[135 107]\n",
      " [ 45  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64       242\n",
      "           1       0.29      0.49      0.36        88\n",
      "\n",
      "    accuracy                           0.54       330\n",
      "   macro avg       0.52      0.52      0.50       330\n",
      "weighted avg       0.63      0.54      0.57       330\n",
      "\n",
      "16/16 [==============================] - 5s 293ms/step - loss: 0.2955 - accuracy: 0.8757 - val_loss: 1.0566 - val_accuracy: 0.5394\n",
      "Epoch 42/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.2718 - accuracy\n",
      "Confusion Matrix after Epoch 42:\n",
      "[[125 117]\n",
      " [ 44  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.52      0.61       242\n",
      "           1       0.27      0.50      0.35        88\n",
      "\n",
      "    accuracy                           0.51       330\n",
      "   macro avg       0.51      0.51      0.48       330\n",
      "weighted avg       0.62      0.51      0.54       330\n",
      "\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.2718 - accuracy: 0.8826 - val_loss: 1.1085 - val_accuracy: 0.5121\n",
      "Epoch 43/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.2491 - accuracy: \n",
      "Confusion Matrix after Epoch 43:\n",
      "[[159  83]\n",
      " [ 53  35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70       242\n",
      "           1       0.30      0.40      0.34        88\n",
      "\n",
      "    accuracy                           0.59       330\n",
      "   macro avg       0.52      0.53      0.52       330\n",
      "weighted avg       0.63      0.59      0.60       330\n",
      "\n",
      "16/16 [==============================] - 5s 318ms/step - loss: 0.2491 - accuracy: 0.8973 - val_loss: 0.9813 - val_accuracy: 0.5879\n",
      "Epoch 44/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.2391 - accuracy: \n",
      "Confusion Matrix after Epoch 44:\n",
      "[[165  77]\n",
      " [ 54  34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.72       242\n",
      "           1       0.31      0.39      0.34        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.60      0.62       330\n",
      "\n",
      "16/16 [==============================] - 5s 320ms/step - loss: 0.2391 - accuracy: 0.9012 - val_loss: 0.9466 - val_accuracy: 0.6030\n",
      "Epoch 45/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.2548 - accuracy: \n",
      "Confusion Matrix after Epoch 45:\n",
      "[[166  76]\n",
      " [ 54  34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       242\n",
      "           1       0.31      0.39      0.34        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.53      0.54      0.53       330\n",
      "weighted avg       0.64      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 0.2548 - accuracy: 0.8865 - val_loss: 1.0288 - val_accuracy: 0.6061\n",
      "Epoch 46/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.2297 - accuracy: \n",
      "Confusion Matrix after Epoch 46:\n",
      "[[162  80]\n",
      " [ 48  40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72       242\n",
      "           1       0.33      0.45      0.38        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.55      0.56      0.55       330\n",
      "weighted avg       0.65      0.61      0.63       330\n",
      "\n",
      "16/16 [==============================] - 6s 365ms/step - loss: 0.2297 - accuracy: 0.9090 - val_loss: 0.9967 - val_accuracy: 0.6121\n",
      "Epoch 47/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.2362 - accuracy: \n",
      "Confusion Matrix after Epoch 47:\n",
      "[[153  89]\n",
      " [ 51  37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.69       242\n",
      "           1       0.29      0.42      0.35        88\n",
      "\n",
      "    accuracy                           0.58       330\n",
      "   macro avg       0.52      0.53      0.52       330\n",
      "weighted avg       0.63      0.58      0.60       330\n",
      "\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 0.2362 - accuracy: 0.9090 - val_loss: 1.0955 - val_accuracy: 0.5758\n",
      "Epoch 48/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.2582 - accuracy: \n",
      "Confusion Matrix after Epoch 48:\n",
      "[[216  26]\n",
      " [ 77  11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81       242\n",
      "           1       0.30      0.12      0.18        88\n",
      "\n",
      "    accuracy                           0.69       330\n",
      "   macro avg       0.52      0.51      0.49       330\n",
      "weighted avg       0.62      0.69      0.64       330\n",
      "\n",
      "16/16 [==============================] - 5s 339ms/step - loss: 0.2582 - accuracy: 0.8914 - val_loss: 1.0895 - val_accuracy: 0.6879\n",
      "Epoch 49/120\n",
      "11/11 [==============================] - 0s 19ms/stepss: 0.2885 - accuracy\n",
      "Confusion Matrix after Epoch 49:\n",
      "[[155  87]\n",
      " [ 56  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68       242\n",
      "           1       0.27      0.36      0.31        88\n",
      "\n",
      "    accuracy                           0.57       330\n",
      "   macro avg       0.50      0.50      0.50       330\n",
      "weighted avg       0.61      0.57      0.58       330\n",
      "\n",
      "16/16 [==============================] - 6s 356ms/step - loss: 0.2885 - accuracy: 0.8796 - val_loss: 1.0366 - val_accuracy: 0.5667\n",
      "Epoch 50/120\n",
      "11/11 [==============================] - 0s 18ms/stepss: 0.2372 - accuracy\n",
      "Confusion Matrix after Epoch 50:\n",
      "[[132 110]\n",
      " [ 40  48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.55      0.64       242\n",
      "           1       0.30      0.55      0.39        88\n",
      "\n",
      "    accuracy                           0.55       330\n",
      "   macro avg       0.54      0.55      0.51       330\n",
      "weighted avg       0.64      0.55      0.57       330\n",
      "\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 0.2372 - accuracy: 0.9129 - val_loss: 1.0967 - val_accuracy: 0.5455\n",
      "Epoch 51/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.2265 - accuracy\n",
      "Confusion Matrix after Epoch 51:\n",
      "[[166  76]\n",
      " [ 52  36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72       242\n",
      "           1       0.32      0.41      0.36        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.54      0.55      0.54       330\n",
      "weighted avg       0.64      0.61      0.63       330\n",
      "\n",
      "16/16 [==============================] - 6s 350ms/step - loss: 0.2265 - accuracy: 0.9119 - val_loss: 1.0949 - val_accuracy: 0.6121\n",
      "Epoch 52/120\n",
      "11/11 [==============================] - 0s 18ms/stepss: 0.2117 - accuracy\n",
      "Confusion Matrix after Epoch 52:\n",
      "[[175  67]\n",
      " [ 54  34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       242\n",
      "           1       0.34      0.39      0.36        88\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.55      0.55      0.55       330\n",
      "weighted avg       0.65      0.63      0.64       330\n",
      "\n",
      "16/16 [==============================] - 6s 378ms/step - loss: 0.2117 - accuracy: 0.9217 - val_loss: 1.0202 - val_accuracy: 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.2303 - accuracy: \n",
      "Confusion Matrix after Epoch 53:\n",
      "[[143  99]\n",
      " [ 50  38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.59      0.66       242\n",
      "           1       0.28      0.43      0.34        88\n",
      "\n",
      "    accuracy                           0.55       330\n",
      "   macro avg       0.51      0.51      0.50       330\n",
      "weighted avg       0.62      0.55      0.57       330\n",
      "\n",
      "16/16 [==============================] - 6s 357ms/step - loss: 0.2303 - accuracy: 0.9051 - val_loss: 1.1874 - val_accuracy: 0.5485\n",
      "Epoch 54/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.2081 - accuracy: \n",
      "Confusion Matrix after Epoch 54:\n",
      "[[136 106]\n",
      " [ 40  48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.56      0.65       242\n",
      "           1       0.31      0.55      0.40        88\n",
      "\n",
      "    accuracy                           0.56       330\n",
      "   macro avg       0.54      0.55      0.52       330\n",
      "weighted avg       0.65      0.56      0.58       330\n",
      "\n",
      "16/16 [==============================] - 6s 365ms/step - loss: 0.2081 - accuracy: 0.9217 - val_loss: 1.2363 - val_accuracy: 0.5576\n",
      "Epoch 55/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.1945 - accuracy: \n",
      "Confusion Matrix after Epoch 55:\n",
      "[[156  86]\n",
      " [ 55  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.69       242\n",
      "           1       0.28      0.38      0.32        88\n",
      "\n",
      "    accuracy                           0.57       330\n",
      "   macro avg       0.51      0.51      0.50       330\n",
      "weighted avg       0.62      0.57      0.59       330\n",
      "\n",
      "16/16 [==============================] - 6s 362ms/step - loss: 0.1945 - accuracy: 0.9178 - val_loss: 1.1740 - val_accuracy: 0.5727\n",
      "Epoch 56/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.2446 - accuracy\n",
      "Confusion Matrix after Epoch 56:\n",
      "[[182  60]\n",
      " [ 63  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75       242\n",
      "           1       0.29      0.28      0.29        88\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.52      0.52      0.52       330\n",
      "weighted avg       0.62      0.63      0.63       330\n",
      "\n",
      "16/16 [==============================] - 6s 374ms/step - loss: 0.2446 - accuracy: 0.8914 - val_loss: 1.0174 - val_accuracy: 0.6273\n",
      "Epoch 57/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.2311 - accuracy: \n",
      "Confusion Matrix after Epoch 57:\n",
      "[[192  50]\n",
      " [ 62  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77       242\n",
      "           1       0.34      0.30      0.32        88\n",
      "\n",
      "    accuracy                           0.66       330\n",
      "   macro avg       0.55      0.54      0.55       330\n",
      "weighted avg       0.65      0.66      0.65       330\n",
      "\n",
      "16/16 [==============================] - 6s 362ms/step - loss: 0.2311 - accuracy: 0.8953 - val_loss: 1.1581 - val_accuracy: 0.6606\n",
      "Epoch 58/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.2093 - accuracy: \n",
      "Confusion Matrix after Epoch 58:\n",
      "[[163  79]\n",
      " [ 50  38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72       242\n",
      "           1       0.32      0.43      0.37        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.55      0.55      0.54       330\n",
      "weighted avg       0.65      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 5s 334ms/step - loss: 0.2093 - accuracy: 0.9149 - val_loss: 1.0629 - val_accuracy: 0.6091\n",
      "Epoch 59/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.1841 - accuracy: \n",
      "Confusion Matrix after Epoch 59:\n",
      "[[164  78]\n",
      " [ 57  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       242\n",
      "           1       0.28      0.35      0.31        88\n",
      "\n",
      "    accuracy                           0.59       330\n",
      "   macro avg       0.51      0.51      0.51       330\n",
      "weighted avg       0.62      0.59      0.60       330\n",
      "\n",
      "16/16 [==============================] - 5s 306ms/step - loss: 0.1841 - accuracy: 0.9354 - val_loss: 1.1075 - val_accuracy: 0.5909\n",
      "Epoch 60/120\n",
      "11/11 [==============================] - 0s 14ms/stepss: 0.1878 - accuracy: \n",
      "Confusion Matrix after Epoch 60:\n",
      "[[146  96]\n",
      " [ 45  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.60      0.67       242\n",
      "           1       0.31      0.49      0.38        88\n",
      "\n",
      "    accuracy                           0.57       330\n",
      "   macro avg       0.54      0.55      0.53       330\n",
      "weighted avg       0.64      0.57      0.60       330\n",
      "\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 0.1878 - accuracy: 0.9276 - val_loss: 1.1461 - val_accuracy: 0.5727\n",
      "Epoch 61/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.2006 - accuracy\n",
      "Confusion Matrix after Epoch 61:\n",
      "[[134 108]\n",
      " [ 42  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.55      0.64       242\n",
      "           1       0.30      0.52      0.38        88\n",
      "\n",
      "    accuracy                           0.55       330\n",
      "   macro avg       0.53      0.54      0.51       330\n",
      "weighted avg       0.64      0.55      0.57       330\n",
      "\n",
      "16/16 [==============================] - 5s 330ms/step - loss: 0.2006 - accuracy: 0.9237 - val_loss: 1.3336 - val_accuracy: 0.5455\n",
      "Epoch 62/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.1860 - accuracy\n",
      "Confusion Matrix after Epoch 62:\n",
      "[[154  88]\n",
      " [ 46  42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.64      0.70       242\n",
      "           1       0.32      0.48      0.39        88\n",
      "\n",
      "    accuracy                           0.59       330\n",
      "   macro avg       0.55      0.56      0.54       330\n",
      "weighted avg       0.65      0.59      0.61       330\n",
      "\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.1860 - accuracy: 0.9335 - val_loss: 1.1529 - val_accuracy: 0.5939\n",
      "Epoch 63/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.1614 - accuracy: \n",
      "Confusion Matrix after Epoch 63:\n",
      "[[152  90]\n",
      " [ 52  36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.68       242\n",
      "           1       0.29      0.41      0.34        88\n",
      "\n",
      "    accuracy                           0.57       330\n",
      "   macro avg       0.52      0.52      0.51       330\n",
      "weighted avg       0.62      0.57      0.59       330\n",
      "\n",
      "16/16 [==============================] - 5s 323ms/step - loss: 0.1614 - accuracy: 0.9344 - val_loss: 1.3286 - val_accuracy: 0.5697\n",
      "Epoch 64/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.1631 - accuracy\n",
      "Confusion Matrix after Epoch 64:\n",
      "[[171  71]\n",
      " [ 57  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       242\n",
      "           1       0.30      0.35      0.33        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 5s 312ms/step - loss: 0.1631 - accuracy: 0.9344 - val_loss: 1.2040 - val_accuracy: 0.6121\n",
      "Epoch 65/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.1496 - accuracy\n",
      "Confusion Matrix after Epoch 65:\n",
      "[[126 116]\n",
      " [ 43  45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.52      0.61       242\n",
      "           1       0.28      0.51      0.36        88\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.51      0.52      0.49       330\n",
      "weighted avg       0.62      0.52      0.55       330\n",
      "\n",
      "16/16 [==============================] - 6s 374ms/step - loss: 0.1496 - accuracy: 0.9374 - val_loss: 1.5648 - val_accuracy: 0.5182\n",
      "Epoch 66/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.1707 - accuracy: \n",
      "Confusion Matrix after Epoch 66:\n",
      "[[165  77]\n",
      " [ 59  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       242\n",
      "           1       0.27      0.33      0.30        88\n",
      "\n",
      "    accuracy                           0.59       330\n",
      "   macro avg       0.51      0.51      0.50       330\n",
      "weighted avg       0.61      0.59      0.60       330\n",
      "\n",
      "16/16 [==============================] - 5s 301ms/step - loss: 0.1707 - accuracy: 0.9364 - val_loss: 1.3177 - val_accuracy: 0.5879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/120\n",
      "11/11 [==============================] - 1s 144ms/steps: 0.1\n",
      "Confusion Matrix after Epoch 67:\n",
      "[[176  66]\n",
      " [ 58  30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       242\n",
      "           1       0.31      0.34      0.33        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.62      0.63       330\n",
      "\n",
      "16/16 [==============================] - 8s 536ms/step - loss: 0.1430 - accuracy: 0.9511 - val_loss: 1.1518 - val_accuracy: 0.6242\n",
      "Epoch 68/120\n",
      "11/11 [==============================] - 1s 133ms/steps: 0.135\n",
      "Confusion Matrix after Epoch 68:\n",
      "[[169  73]\n",
      " [ 57  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72       242\n",
      "           1       0.30      0.35      0.32        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.52      0.53      0.52       330\n",
      "weighted avg       0.63      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 13s 780ms/step - loss: 0.1359 - accuracy: 0.9521 - val_loss: 1.2337 - val_accuracy: 0.6061\n",
      "Epoch 69/120\n",
      "11/11 [==============================] - 2s 148ms/steps: 0.1\n",
      "Confusion Matrix after Epoch 69:\n",
      "[[175  67]\n",
      " [ 56  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       242\n",
      "           1       0.32      0.36      0.34        88\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.54      0.54      0.54       330\n",
      "weighted avg       0.64      0.63      0.63       330\n",
      "\n",
      "16/16 [==============================] - 13s 785ms/step - loss: 0.1417 - accuracy: 0.9452 - val_loss: 1.2587 - val_accuracy: 0.6273\n",
      "Epoch 70/120\n",
      "11/11 [==============================] - 2s 138ms/steps: 0.127\n",
      "Confusion Matrix after Epoch 70:\n",
      "[[183  59]\n",
      " [ 67  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       242\n",
      "           1       0.26      0.24      0.25        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.50      0.50      0.50       330\n",
      "weighted avg       0.61      0.62      0.61       330\n",
      "\n",
      "16/16 [==============================] - 13s 814ms/step - loss: 0.1277 - accuracy: 0.9560 - val_loss: 1.3136 - val_accuracy: 0.6182\n",
      "Epoch 71/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.1178 - accuracy\n",
      "Confusion Matrix after Epoch 71:\n",
      "[[138 104]\n",
      " [ 49  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.57      0.64       242\n",
      "           1       0.27      0.44      0.34        88\n",
      "\n",
      "    accuracy                           0.54       330\n",
      "   macro avg       0.51      0.51      0.49       330\n",
      "weighted avg       0.61      0.54      0.56       330\n",
      "\n",
      "16/16 [==============================] - 9s 594ms/step - loss: 0.1178 - accuracy: 0.9628 - val_loss: 1.5884 - val_accuracy: 0.5364\n",
      "Epoch 72/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.1217 - accuracy: \n",
      "Confusion Matrix after Epoch 72:\n",
      "[[156  86]\n",
      " [ 52  36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       242\n",
      "           1       0.30      0.41      0.34        88\n",
      "\n",
      "    accuracy                           0.58       330\n",
      "   macro avg       0.52      0.53      0.52       330\n",
      "weighted avg       0.63      0.58      0.60       330\n",
      "\n",
      "16/16 [==============================] - 5s 328ms/step - loss: 0.1217 - accuracy: 0.9560 - val_loss: 1.4258 - val_accuracy: 0.5818\n",
      "Epoch 73/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.1133 - accuracy: \n",
      "Confusion Matrix after Epoch 73:\n",
      "[[158  84]\n",
      " [ 51  37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70       242\n",
      "           1       0.31      0.42      0.35        88\n",
      "\n",
      "    accuracy                           0.59       330\n",
      "   macro avg       0.53      0.54      0.53       330\n",
      "weighted avg       0.64      0.59      0.61       330\n",
      "\n",
      "16/16 [==============================] - 5s 317ms/step - loss: 0.1133 - accuracy: 0.9677 - val_loss: 1.3933 - val_accuracy: 0.5909\n",
      "Epoch 74/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.1079 - accuracy: \n",
      "Confusion Matrix after Epoch 74:\n",
      "[[176  66]\n",
      " [ 62  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.73       242\n",
      "           1       0.28      0.30      0.29        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.51      0.51      0.51       330\n",
      "weighted avg       0.62      0.61      0.61       330\n",
      "\n",
      "16/16 [==============================] - 5s 329ms/step - loss: 0.1079 - accuracy: 0.9638 - val_loss: 1.3583 - val_accuracy: 0.6121\n",
      "Epoch 75/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.1156 - accuracy: \n",
      "Confusion Matrix after Epoch 75:\n",
      "[[180  62]\n",
      " [ 66  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       242\n",
      "           1       0.26      0.25      0.26        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.50      0.50      0.50       330\n",
      "weighted avg       0.61      0.61      0.61       330\n",
      "\n",
      "16/16 [==============================] - 5s 317ms/step - loss: 0.1156 - accuracy: 0.9560 - val_loss: 1.4259 - val_accuracy: 0.6121\n",
      "Epoch 76/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.1413 - accuracy: \n",
      "Confusion Matrix after Epoch 76:\n",
      "[[155  87]\n",
      " [ 54  34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.69       242\n",
      "           1       0.28      0.39      0.33        88\n",
      "\n",
      "    accuracy                           0.57       330\n",
      "   macro avg       0.51      0.51      0.51       330\n",
      "weighted avg       0.62      0.57      0.59       330\n",
      "\n",
      "16/16 [==============================] - 5s 303ms/step - loss: 0.1413 - accuracy: 0.9423 - val_loss: 1.5673 - val_accuracy: 0.5727\n",
      "Epoch 77/120\n",
      "11/11 [==============================] - 0s 19ms/stepss: 0.1365 - accuracy\n",
      "Confusion Matrix after Epoch 77:\n",
      "[[185  57]\n",
      " [ 64  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       242\n",
      "           1       0.30      0.27      0.28        88\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.52      0.52      0.52       330\n",
      "weighted avg       0.62      0.63      0.63       330\n",
      "\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.1365 - accuracy: 0.9481 - val_loss: 1.4566 - val_accuracy: 0.6333\n",
      "Epoch 78/120\n",
      "11/11 [==============================] - 0s 18ms/stepss: 0.1347 - accuracy\n",
      "Confusion Matrix after Epoch 78:\n",
      "[[171  71]\n",
      " [ 57  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       242\n",
      "           1       0.30      0.35      0.33        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 5s 327ms/step - loss: 0.1347 - accuracy: 0.9481 - val_loss: 1.4837 - val_accuracy: 0.6121\n",
      "Epoch 79/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.1006 - accuracy\n",
      "Confusion Matrix after Epoch 79:\n",
      "[[166  76]\n",
      " [ 57  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       242\n",
      "           1       0.29      0.35      0.32        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.52      0.52      0.52       330\n",
      "weighted avg       0.62      0.60      0.61       330\n",
      "\n",
      "16/16 [==============================] - 5s 310ms/step - loss: 0.1006 - accuracy: 0.9726 - val_loss: 1.5167 - val_accuracy: 0.5970\n",
      "Epoch 80/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.0958 - accuracy\n",
      "Confusion Matrix after Epoch 80:\n",
      "[[161  81]\n",
      " [ 52  36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       242\n",
      "           1       0.31      0.41      0.35        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.53      0.54      0.53       330\n",
      "weighted avg       0.64      0.60      0.61       330\n",
      "\n",
      "16/16 [==============================] - 5s 309ms/step - loss: 0.0958 - accuracy: 0.9736 - val_loss: 1.4118 - val_accuracy: 0.5970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/120\n",
      "11/11 [==============================] - 0s 15ms/stepss: 0.0949 - accuracy: \n",
      "Confusion Matrix after Epoch 81:\n",
      "[[183  59]\n",
      " [ 64  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       242\n",
      "           1       0.29      0.27      0.28        88\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.52      0.51      0.51       330\n",
      "weighted avg       0.62      0.63      0.62       330\n",
      "\n",
      "16/16 [==============================] - 5s 310ms/step - loss: 0.0949 - accuracy: 0.9716 - val_loss: 1.5028 - val_accuracy: 0.6273\n",
      "Epoch 82/120\n",
      "11/11 [==============================] - 0s 16ms/stepss: 0.1190 - accuracy: \n",
      "Confusion Matrix after Epoch 82:\n",
      "[[175  67]\n",
      " [ 57  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74       242\n",
      "           1       0.32      0.35      0.33        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.54      0.54      0.54       330\n",
      "weighted avg       0.64      0.62      0.63       330\n",
      "\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.1190 - accuracy: 0.9560 - val_loss: 1.5460 - val_accuracy: 0.6242\n",
      "Epoch 83/120\n",
      "11/11 [==============================] - 0s 18ms/stepss: 0.1168 - accuracy: \n",
      "Confusion Matrix after Epoch 83:\n",
      "[[165  77]\n",
      " [ 49  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       242\n",
      "           1       0.34      0.44      0.38        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.55      0.56      0.55       330\n",
      "weighted avg       0.66      0.62      0.63       330\n",
      "\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 0.1168 - accuracy: 0.9579 - val_loss: 1.4926 - val_accuracy: 0.6182\n",
      "Epoch 84/120\n",
      "11/11 [==============================] - 0s 17ms/stepss: 0.1110 - accuracy: \n",
      "Confusion Matrix after Epoch 84:\n",
      "[[160  82]\n",
      " [ 48  40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.66      0.71       242\n",
      "           1       0.33      0.45      0.38        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.55      0.56      0.55       330\n",
      "weighted avg       0.65      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 5s 324ms/step - loss: 0.1110 - accuracy: 0.9648 - val_loss: 1.5356 - val_accuracy: 0.6061\n",
      "Epoch 85/120\n",
      "11/11 [==============================] - 1s 54ms/stepss: 0.1054 - accura\n",
      "Confusion Matrix after Epoch 85:\n",
      "[[150  92]\n",
      " [ 50  38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68       242\n",
      "           1       0.29      0.43      0.35        88\n",
      "\n",
      "    accuracy                           0.57       330\n",
      "   macro avg       0.52      0.53      0.51       330\n",
      "weighted avg       0.63      0.57      0.59       330\n",
      "\n",
      "16/16 [==============================] - 7s 441ms/step - loss: 0.1054 - accuracy: 0.9667 - val_loss: 1.5521 - val_accuracy: 0.5697\n",
      "Epoch 86/120\n",
      "11/11 [==============================] - 1s 91ms/stepss: 0.0938 - ac\n",
      "Confusion Matrix after Epoch 86:\n",
      "[[163  79]\n",
      " [ 53  35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71       242\n",
      "           1       0.31      0.40      0.35        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.53      0.54      0.53       330\n",
      "weighted avg       0.64      0.60      0.61       330\n",
      "\n",
      "16/16 [==============================] - 12s 789ms/step - loss: 0.0938 - accuracy: 0.9716 - val_loss: 1.6013 - val_accuracy: 0.6000\n",
      "Epoch 87/120\n",
      "11/11 [==============================] - 1s 103ms/steps: 0.0927 - ac\n",
      "Confusion Matrix after Epoch 87:\n",
      "[[165  77]\n",
      " [ 57  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       242\n",
      "           1       0.29      0.35      0.32        88\n",
      "\n",
      "    accuracy                           0.59       330\n",
      "   macro avg       0.52      0.52      0.51       330\n",
      "weighted avg       0.62      0.59      0.61       330\n",
      "\n",
      "16/16 [==============================] - 12s 787ms/step - loss: 0.0927 - accuracy: 0.9716 - val_loss: 1.5782 - val_accuracy: 0.5939\n",
      "Epoch 88/120\n",
      "11/11 [==============================] - 1s 109ms/steps: 0.0951 - \n",
      "Confusion Matrix after Epoch 88:\n",
      "[[170  72]\n",
      " [ 56  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.73       242\n",
      "           1       0.31      0.36      0.33        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 12s 789ms/step - loss: 0.0951 - accuracy: 0.9648 - val_loss: 1.5921 - val_accuracy: 0.6121\n",
      "Epoch 89/120\n",
      "11/11 [==============================] - 0s 22ms/stepss: 0.0907 - accuracy\n",
      "Confusion Matrix after Epoch 89:\n",
      "[[180  62]\n",
      " [ 60  28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75       242\n",
      "           1       0.31      0.32      0.31        88\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.63      0.63       330\n",
      "\n",
      "16/16 [==============================] - 11s 702ms/step - loss: 0.0907 - accuracy: 0.9687 - val_loss: 1.5152 - val_accuracy: 0.6303\n",
      "Epoch 90/120\n",
      "11/11 [==============================] - 1s 122ms/steps: 0.083\n",
      "Confusion Matrix after Epoch 90:\n",
      "[[161  81]\n",
      " [ 52  36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       242\n",
      "           1       0.31      0.41      0.35        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.53      0.54      0.53       330\n",
      "weighted avg       0.64      0.60      0.61       330\n",
      "\n",
      "16/16 [==============================] - 12s 753ms/step - loss: 0.0833 - accuracy: 0.9755 - val_loss: 1.5899 - val_accuracy: 0.5970\n",
      "Epoch 91/120\n",
      "11/11 [==============================] - 2s 147ms/steps: 0.0\n",
      "Confusion Matrix after Epoch 91:\n",
      "[[169  73]\n",
      " [ 56  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72       242\n",
      "           1       0.30      0.36      0.33        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 13s 790ms/step - loss: 0.0868 - accuracy: 0.9736 - val_loss: 1.5769 - val_accuracy: 0.6091\n",
      "Epoch 92/120\n",
      "11/11 [==============================] - 1s 133ms/steps: 0.1\n",
      "Confusion Matrix after Epoch 92:\n",
      "[[172  70]\n",
      " [ 60  28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73       242\n",
      "           1       0.29      0.32      0.30        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.51      0.51      0.51       330\n",
      "weighted avg       0.62      0.61      0.61       330\n",
      "\n",
      "16/16 [==============================] - 12s 766ms/step - loss: 0.1107 - accuracy: 0.9589 - val_loss: 1.6515 - val_accuracy: 0.6061\n",
      "Epoch 93/120\n",
      "11/11 [==============================] - 2s 151ms/steps: 0.0\n",
      "Confusion Matrix after Epoch 93:\n",
      "[[154  88]\n",
      " [ 49  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.64      0.69       242\n",
      "           1       0.31      0.44      0.36        88\n",
      "\n",
      "    accuracy                           0.58       330\n",
      "   macro avg       0.53      0.54      0.53       330\n",
      "weighted avg       0.64      0.58      0.60       330\n",
      "\n",
      "16/16 [==============================] - 12s 758ms/step - loss: 0.0972 - accuracy: 0.9658 - val_loss: 1.6275 - val_accuracy: 0.5848\n",
      "Epoch 94/120\n",
      "11/11 [==============================] - 1s 69ms/stepss: 0.1125 - ac\n",
      "Confusion Matrix after Epoch 94:\n",
      "[[173  69]\n",
      " [ 55  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.74       242\n",
      "           1       0.32      0.38      0.35        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.54      0.54      0.54       330\n",
      "weighted avg       0.64      0.62      0.63       330\n",
      "\n",
      "16/16 [==============================] - 9s 541ms/step - loss: 0.1125 - accuracy: 0.9540 - val_loss: 1.6112 - val_accuracy: 0.6242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/120\n",
      "11/11 [==============================] - 1s 98ms/stepss: 0.1233 - ac\n",
      "Confusion Matrix after Epoch 95:\n",
      "[[180  62]\n",
      " [ 63  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       242\n",
      "           1       0.29      0.28      0.29        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.51      0.51      0.51       330\n",
      "weighted avg       0.62      0.62      0.62       330\n",
      "\n",
      "16/16 [==============================] - 12s 743ms/step - loss: 0.1233 - accuracy: 0.9550 - val_loss: 1.4963 - val_accuracy: 0.6212\n",
      "Epoch 96/120\n",
      "11/11 [==============================] - 1s 120ms/steps: 0.0994 - \n",
      "Confusion Matrix after Epoch 96:\n",
      "[[180  62]\n",
      " [ 67  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       242\n",
      "           1       0.25      0.24      0.25        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.49      0.49      0.49       330\n",
      "weighted avg       0.60      0.61      0.61       330\n",
      "\n",
      "16/16 [==============================] - 12s 759ms/step - loss: 0.0994 - accuracy: 0.9716 - val_loss: 1.5388 - val_accuracy: 0.6091\n",
      "Epoch 97/120\n",
      "11/11 [==============================] - 1s 113ms/steps: 0.1008 \n",
      "Confusion Matrix after Epoch 97:\n",
      "[[180  62]\n",
      " [ 62  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       242\n",
      "           1       0.30      0.30      0.30        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.52      0.52      0.52       330\n",
      "weighted avg       0.62      0.62      0.62       330\n",
      "\n",
      "16/16 [==============================] - 11s 737ms/step - loss: 0.1008 - accuracy: 0.9658 - val_loss: 1.3784 - val_accuracy: 0.6242\n",
      "Epoch 98/120\n",
      "11/11 [==============================] - 1s 114ms/steps: 0.091\n",
      "Confusion Matrix after Epoch 98:\n",
      "[[177  65]\n",
      " [ 61  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74       242\n",
      "           1       0.29      0.31      0.30        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.52      0.52      0.52       330\n",
      "weighted avg       0.62      0.62      0.62       330\n",
      "\n",
      "16/16 [==============================] - 9s 603ms/step - loss: 0.0919 - accuracy: 0.9667 - val_loss: 1.4784 - val_accuracy: 0.6182\n",
      "Epoch 99/120\n",
      "11/11 [==============================] - 1s 135ms/steps: 0.0\n",
      "Confusion Matrix after Epoch 99:\n",
      "[[184  58]\n",
      " [ 66  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       242\n",
      "           1       0.28      0.25      0.26        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.51      0.51      0.50       330\n",
      "weighted avg       0.61      0.62      0.62       330\n",
      "\n",
      "16/16 [==============================] - 12s 779ms/step - loss: 0.0923 - accuracy: 0.9755 - val_loss: 1.5337 - val_accuracy: 0.6242\n",
      "Epoch 100/120\n",
      "11/11 [==============================] - 2s 146ms/steps: 0.1\n",
      "Confusion Matrix after Epoch 100:\n",
      "[[163  79]\n",
      " [ 52  36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       242\n",
      "           1       0.31      0.41      0.35        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.54      0.54      0.53       330\n",
      "weighted avg       0.64      0.60      0.62       330\n",
      "\n",
      "16/16 [==============================] - 12s 741ms/step - loss: 0.1147 - accuracy: 0.9618 - val_loss: 1.6021 - val_accuracy: 0.6030\n",
      "Epoch 101/120\n",
      "11/11 [==============================] - 1s 131ms/steps: 0.078\n",
      "Confusion Matrix after Epoch 101:\n",
      "[[171  71]\n",
      " [ 57  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       242\n",
      "           1       0.30      0.35      0.33        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 12s 739ms/step - loss: 0.0788 - accuracy: 0.9736 - val_loss: 1.5510 - val_accuracy: 0.6121\n",
      "Epoch 102/120\n",
      "11/11 [==============================] - 0s 24ms/stepss: 0.0790 - accuracy\n",
      "Confusion Matrix after Epoch 102:\n",
      "[[165  77]\n",
      " [ 55  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71       242\n",
      "           1       0.30      0.38      0.33        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.53      0.53      0.52       330\n",
      "weighted avg       0.63      0.60      0.61       330\n",
      "\n",
      "16/16 [==============================] - 11s 668ms/step - loss: 0.0790 - accuracy: 0.9755 - val_loss: 1.6666 - val_accuracy: 0.6000\n",
      "Epoch 103/120\n",
      "11/11 [==============================] - 2s 151ms/steps: 0.0656 \n",
      "Confusion Matrix after Epoch 103:\n",
      "[[161  81]\n",
      " [ 52  36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       242\n",
      "           1       0.31      0.41      0.35        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.53      0.54      0.53       330\n",
      "weighted avg       0.64      0.60      0.61       330\n",
      "\n",
      "16/16 [==============================] - 11s 680ms/step - loss: 0.0656 - accuracy: 0.9853 - val_loss: 1.8080 - val_accuracy: 0.5970\n",
      "Epoch 104/120\n",
      "11/11 [==============================] - 1s 122ms/steps: 0.0634 \n",
      "Confusion Matrix after Epoch 104:\n",
      "[[154  88]\n",
      " [ 48  40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.64      0.69       242\n",
      "           1       0.31      0.45      0.37        88\n",
      "\n",
      "    accuracy                           0.59       330\n",
      "   macro avg       0.54      0.55      0.53       330\n",
      "weighted avg       0.64      0.59      0.61       330\n",
      "\n",
      "16/16 [==============================] - 12s 754ms/step - loss: 0.0634 - accuracy: 0.9814 - val_loss: 1.9506 - val_accuracy: 0.5879\n",
      "Epoch 105/120\n",
      "11/11 [==============================] - 1s 91ms/stepss: 0.0731 - ac\n",
      "Confusion Matrix after Epoch 105:\n",
      "[[166  76]\n",
      " [ 59  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       242\n",
      "           1       0.28      0.33      0.30        88\n",
      "\n",
      "    accuracy                           0.59       330\n",
      "   macro avg       0.51      0.51      0.51       330\n",
      "weighted avg       0.61      0.59      0.60       330\n",
      "\n",
      "16/16 [==============================] - 12s 751ms/step - loss: 0.0731 - accuracy: 0.9775 - val_loss: 1.6880 - val_accuracy: 0.5909\n",
      "Epoch 106/120\n",
      "11/11 [==============================] - 1s 131ms/steps: 0.0611 \n",
      "Confusion Matrix after Epoch 106:\n",
      "[[167  75]\n",
      " [ 56  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       242\n",
      "           1       0.30      0.36      0.33        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.52      0.53      0.52       330\n",
      "weighted avg       0.63      0.60      0.61       330\n",
      "\n",
      "16/16 [==============================] - 12s 753ms/step - loss: 0.0611 - accuracy: 0.9843 - val_loss: 1.7001 - val_accuracy: 0.6030\n",
      "Epoch 107/120\n",
      "11/11 [==============================] - 1s 42ms/stepss: 0.0542 - accu\n",
      "Confusion Matrix after Epoch 107:\n",
      "[[175  67]\n",
      " [ 61  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73       242\n",
      "           1       0.29      0.31      0.30        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.51      0.51      0.51       330\n",
      "weighted avg       0.62      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 9s 580ms/step - loss: 0.0542 - accuracy: 0.9804 - val_loss: 1.6779 - val_accuracy: 0.6121\n",
      "Epoch 108/120\n",
      "11/11 [==============================] - 1s 43ms/stepss: 0.0619 - accu\n",
      "Confusion Matrix after Epoch 108:\n",
      "[[162  80]\n",
      " [ 52  36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       242\n",
      "           1       0.31      0.41      0.35        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.53      0.54      0.53       330\n",
      "weighted avg       0.64      0.60      0.62       330\n",
      "\n",
      "16/16 [==============================] - 11s 714ms/step - loss: 0.0619 - accuracy: 0.9873 - val_loss: 1.7944 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/120\n",
      "11/11 [==============================] - 1s 83ms/stepss: 0.0546 - ac\n",
      "Confusion Matrix after Epoch 109:\n",
      "[[178  64]\n",
      " [ 59  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74       242\n",
      "           1       0.31      0.33      0.32        88\n",
      "\n",
      "    accuracy                           0.63       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.63      0.63       330\n",
      "\n",
      "16/16 [==============================] - 12s 734ms/step - loss: 0.0546 - accuracy: 0.9834 - val_loss: 1.7370 - val_accuracy: 0.6273\n",
      "Epoch 110/120\n",
      "11/11 [==============================] - 1s 92ms/stepss: 0.0519 - ac\n",
      "Confusion Matrix after Epoch 110:\n",
      "[[167  75]\n",
      " [ 55  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       242\n",
      "           1       0.31      0.38      0.34        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 12s 764ms/step - loss: 0.0519 - accuracy: 0.9843 - val_loss: 1.7856 - val_accuracy: 0.6061\n",
      "Epoch 111/120\n",
      "11/11 [==============================] - 0s 22ms/stepss: 0.0489 - accuracy\n",
      "Confusion Matrix after Epoch 111:\n",
      "[[160  82]\n",
      " [ 50  38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.66      0.71       242\n",
      "           1       0.32      0.43      0.37        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.54      0.55      0.54       330\n",
      "weighted avg       0.64      0.60      0.62       330\n",
      "\n",
      "16/16 [==============================] - 11s 660ms/step - loss: 0.0489 - accuracy: 0.9892 - val_loss: 1.7448 - val_accuracy: 0.6000\n",
      "Epoch 112/120\n",
      "11/11 [==============================] - 1s 127ms/steps: 0.0\n",
      "Confusion Matrix after Epoch 112:\n",
      "[[156  86]\n",
      " [ 51  37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       242\n",
      "           1       0.30      0.42      0.35        88\n",
      "\n",
      "    accuracy                           0.58       330\n",
      "   macro avg       0.53      0.53      0.52       330\n",
      "weighted avg       0.63      0.58      0.60       330\n",
      "\n",
      "16/16 [==============================] - 12s 780ms/step - loss: 0.0509 - accuracy: 0.9834 - val_loss: 1.9356 - val_accuracy: 0.5848\n",
      "Epoch 113/120\n",
      "11/11 [==============================] - 1s 125ms/steps: 0.047\n",
      "Confusion Matrix after Epoch 113:\n",
      "[[170  72]\n",
      " [ 61  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       242\n",
      "           1       0.27      0.31      0.29        88\n",
      "\n",
      "    accuracy                           0.60       330\n",
      "   macro avg       0.50      0.50      0.50       330\n",
      "weighted avg       0.61      0.60      0.60       330\n",
      "\n",
      "16/16 [==============================] - 12s 753ms/step - loss: 0.0475 - accuracy: 0.9873 - val_loss: 1.7677 - val_accuracy: 0.5970\n",
      "Epoch 114/120\n",
      "11/11 [==============================] - 2s 144ms/steps: 0.0\n",
      "Confusion Matrix after Epoch 114:\n",
      "[[177  65]\n",
      " [ 62  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74       242\n",
      "           1       0.29      0.30      0.29        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.51      0.51      0.51       330\n",
      "weighted avg       0.62      0.62      0.62       330\n",
      "\n",
      "16/16 [==============================] - 12s 759ms/step - loss: 0.0504 - accuracy: 0.9863 - val_loss: 1.7558 - val_accuracy: 0.6152\n",
      "Epoch 115/120\n",
      "11/11 [==============================] - 2s 152ms/steps: 0.0\n",
      "Confusion Matrix after Epoch 115:\n",
      "[[177  65]\n",
      " [ 59  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       242\n",
      "           1       0.31      0.33      0.32        88\n",
      "\n",
      "    accuracy                           0.62       330\n",
      "   macro avg       0.53      0.53      0.53       330\n",
      "weighted avg       0.63      0.62      0.63       330\n",
      "\n",
      "16/16 [==============================] - 13s 796ms/step - loss: 0.0433 - accuracy: 0.9902 - val_loss: 1.8314 - val_accuracy: 0.6242\n",
      "Epoch 116/120\n",
      "11/11 [==============================] - 1s 65ms/stepss: 0.0336 - accu\n",
      "Confusion Matrix after Epoch 116:\n",
      "[[163  79]\n",
      " [ 55  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71       242\n",
      "           1       0.29      0.38      0.33        88\n",
      "\n",
      "    accuracy                           0.59       330\n",
      "   macro avg       0.52      0.52      0.52       330\n",
      "weighted avg       0.63      0.59      0.61       330\n",
      "\n",
      "16/16 [==============================] - 9s 537ms/step - loss: 0.0336 - accuracy: 0.9932 - val_loss: 1.9664 - val_accuracy: 0.5939\n",
      "Epoch 117/120\n",
      "11/11 [==============================] - 1s 74ms/stepss: 0.0422 - ac\n",
      "Confusion Matrix after Epoch 117:\n",
      "[[161  81]\n",
      " [ 49  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.71       242\n",
      "           1       0.33      0.44      0.38        88\n",
      "\n",
      "    accuracy                           0.61       330\n",
      "   macro avg       0.55      0.55      0.54       330\n",
      "weighted avg       0.65      0.61      0.62       330\n",
      "\n",
      "16/16 [==============================] - 12s 753ms/step - loss: 0.0422 - accuracy: 0.9863 - val_loss: 1.9099 - val_accuracy: 0.6061\n",
      "Epoch 118/120\n",
      "11/11 [==============================] - 1s 92ms/stepss: 0.0524 - ac\n",
      "Confusion Matrix after Epoch 118:\n",
      "[[157  85]\n",
      " [ 54  34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.69       242\n",
      "           1       0.29      0.39      0.33        88\n",
      "\n",
      "    accuracy                           0.58       330\n",
      "   macro avg       0.51      0.52      0.51       330\n",
      "weighted avg       0.62      0.58      0.60       330\n",
      "\n",
      "16/16 [==============================] - 12s 749ms/step - loss: 0.0524 - accuracy: 0.9853 - val_loss: 1.8824 - val_accuracy: 0.5788\n",
      "Epoch 119/120\n",
      "11/11 [==============================] - 1s 72ms/stepss: 0.0478 - ac\n",
      "Confusion Matrix after Epoch 119:\n",
      "[[146  96]\n",
      " [ 51  37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.60      0.67       242\n",
      "           1       0.28      0.42      0.33        88\n",
      "\n",
      "    accuracy                           0.55       330\n",
      "   macro avg       0.51      0.51      0.50       330\n",
      "weighted avg       0.62      0.55      0.58       330\n",
      "\n",
      "16/16 [==============================] - 12s 781ms/step - loss: 0.0478 - accuracy: 0.9843 - val_loss: 2.0012 - val_accuracy: 0.5545\n",
      "Epoch 120/120\n",
      "11/11 [==============================] - 2s 159ms/steps: 0.0\n",
      "Confusion Matrix after Epoch 120:\n",
      "[[187  55]\n",
      " [ 61  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       242\n",
      "           1       0.33      0.31      0.32        88\n",
      "\n",
      "    accuracy                           0.65       330\n",
      "   macro avg       0.54      0.54      0.54       330\n",
      "weighted avg       0.64      0.65      0.64       330\n",
      "\n",
      "16/16 [==============================] - 10s 649ms/step - loss: 0.0500 - accuracy: 0.9843 - val_loss: 1.7267 - val_accuracy: 0.6485\n"
     ]
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 30)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=11,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=30,\n",
    "    min_lr=0.000001,\n",
    "    verbose=1,\n",
    ")\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class ConfusionMatrixCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        self.validation_data = validation_data\n",
    "        self.relist={}\n",
    "        self.acc=[]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        X_val, y_val = self.validation_data\n",
    "        y_pred = self.model.predict(X_val)\n",
    "        y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "        y_pred_binary = y_pred_binary.reshape(-1, 1)\n",
    "\n",
    "\n",
    "        cm = confusion_matrix(y_val, y_pred_binary)\n",
    "        print(f\"Confusion Matrix after Epoch {epoch + 1}:\\n{cm}\")\n",
    "        print(classification_report(y_test,y_pred_binary))\n",
    "        acc = float(classification_report(y_test,y_pred_binary).split('\\n')[3].split()[2])\n",
    "        self.acc.append(acc)\n",
    "        self.relist[acc]=y_pred_binary\n",
    "\n",
    "# ... Định nghĩa mô hình ...\n",
    "\n",
    "# Tạo đối tượng callback\n",
    "confusion_matrix_callback = ConfusionMatrixCallback(validation_data=(x_test,y_test))\n",
    "\n",
    "callbacks = [early_stopping,lr_scheduler]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = \"Emotion_weights.hdf5\", verbose = 1, save_best_only=True)\n",
    "\n",
    "history=model.fit(x=x_train,y=y_train,\n",
    "          validation_data=(x_test,y_test),\n",
    "          batch_size=64,epochs=120, callbacks=[confusion_matrix_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f237724f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce792290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 155ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       242\n",
      "           1       0.33      0.31      0.32        88\n",
      "\n",
      "    accuracy                           0.65       330\n",
      "   macro avg       0.54      0.54      0.54       330\n",
      "weighted avg       0.64      0.65      0.64       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "y_pred_binary = y_pred_binary.reshape(-1, 1)\n",
    "\n",
    "print(classification_report(y_test,y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8077c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
