{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a18d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c1d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_dir = \"../../exps\"\n",
    "if os.path.exists(exps_dir) == False: # tạo thư mục (nếu chưa có)\n",
    "  os.makedirs(exps_dir, exist_ok=True)\n",
    "\n",
    "save_dir = f\"{exps_dir}/feature1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ec4613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_sex</th>\n",
       "      <th>insured_education_level</th>\n",
       "      <th>insured_occupation</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>day_policy_bind_date</th>\n",
       "      <th>month_policy_bind_date</th>\n",
       "      <th>year_policy_bind_date</th>\n",
       "      <th>day_incident_date</th>\n",
       "      <th>month_incident_date</th>\n",
       "      <th>year_incident_date</th>\n",
       "      <th>week_incident_date</th>\n",
       "      <th>high_week</th>\n",
       "      <th>high_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.770734</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.579574</td>\n",
       "      <td>-0.179439</td>\n",
       "      <td>-1.020460</td>\n",
       "      <td>-1.393943</td>\n",
       "      <td>-0.947412</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.705084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.979562</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.547936</td>\n",
       "      <td>-0.179439</td>\n",
       "      <td>0.908584</td>\n",
       "      <td>0.115223</td>\n",
       "      <td>0.953085</td>\n",
       "      <td>0</td>\n",
       "      <td>1.136723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.675544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.481582</td>\n",
       "      <td>0.108179</td>\n",
       "      <td>-0.744883</td>\n",
       "      <td>0.115223</td>\n",
       "      <td>-0.947412</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.893139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.492901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.368831</td>\n",
       "      <td>-0.467057</td>\n",
       "      <td>1.735317</td>\n",
       "      <td>-1.626123</td>\n",
       "      <td>2.853582</td>\n",
       "      <td>0</td>\n",
       "      <td>1.542695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.613672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.128570</td>\n",
       "      <td>0.971032</td>\n",
       "      <td>1.735317</td>\n",
       "      <td>1.160031</td>\n",
       "      <td>-0.947412</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.487167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.393488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.908354</td>\n",
       "      <td>0.656524</td>\n",
       "      <td>0.393463</td>\n",
       "      <td>-0.917630</td>\n",
       "      <td>-0.947412</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.409131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.839585</td>\n",
       "      <td>-0.592273</td>\n",
       "      <td>1.479683</td>\n",
       "      <td>0.680663</td>\n",
       "      <td>0.953085</td>\n",
       "      <td>0</td>\n",
       "      <td>1.071228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.077354</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.883912</td>\n",
       "      <td>-0.196871</td>\n",
       "      <td>-1.006542</td>\n",
       "      <td>-0.093503</td>\n",
       "      <td>0.914690</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706145</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.839075</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355841</td>\n",
       "      <td>-0.752419</td>\n",
       "      <td>0.704873</td>\n",
       "      <td>0.118865</td>\n",
       "      <td>0.953085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.070194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917317</td>\n",
       "      <td>-0.750775</td>\n",
       "      <td>1.459428</td>\n",
       "      <td>-0.233308</td>\n",
       "      <td>-0.947412</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.893139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      months_as_customer  age  policy_state  policy_csl  policy_deductable  \\\n",
       "0                      2    0             0           1                  1   \n",
       "1                      0    2             1           0                  2   \n",
       "2                      2    0             2           0                  2   \n",
       "3                      2    0             0           0                  2   \n",
       "4                      2    0             2           1                  1   \n",
       "...                  ...  ...           ...         ...                ...   \n",
       "1017                   2    0             2           0                  2   \n",
       "1018                   1    0             0           0                  0   \n",
       "1019                   0    0             1           0                  1   \n",
       "1020                   0    0             1           0                  0   \n",
       "1021                   1    0             0           1                  0   \n",
       "\n",
       "      policy_annual_premium  umbrella_limit  insured_sex  \\\n",
       "0                 -1.770734               0            1   \n",
       "1                 -1.979562               0            1   \n",
       "2                  0.675544               0            0   \n",
       "3                 -0.492901               0            0   \n",
       "4                  0.613672               0            1   \n",
       "...                     ...             ...          ...   \n",
       "1017              -1.393488               0            0   \n",
       "1018               0.661055               0            0   \n",
       "1019              -0.077354               5            1   \n",
       "1020              -0.839075               3            0   \n",
       "1021              -0.070194               0            1   \n",
       "\n",
       "      insured_education_level  insured_occupation  ...  auto_year  \\\n",
       "0                           2                  11  ...          2   \n",
       "1                           4                  11  ...          0   \n",
       "2                           0                   5  ...          1   \n",
       "3                           2                   2  ...          0   \n",
       "4                           4                   2  ...          1   \n",
       "...                       ...                 ...  ...        ...   \n",
       "1017                        0                   6  ...          1   \n",
       "1018                        1                   3  ...          0   \n",
       "1019                        4                   3  ...          1   \n",
       "1020                        5                   5  ...          1   \n",
       "1021                        3                   3  ...          0   \n",
       "\n",
       "      day_policy_bind_date  month_policy_bind_date  year_policy_bind_date  \\\n",
       "0                 0.579574               -0.179439              -1.020460   \n",
       "1                -0.547936               -0.179439               0.908584   \n",
       "2                 1.481582                0.108179              -0.744883   \n",
       "3                 1.368831               -0.467057               1.735317   \n",
       "4                 0.128570                0.971032               1.735317   \n",
       "...                    ...                     ...                    ...   \n",
       "1017              0.908354                0.656524               0.393463   \n",
       "1018              0.839585               -0.592273               1.479683   \n",
       "1019             -0.883912               -0.196871              -1.006542   \n",
       "1020              0.355841               -0.752419               0.704873   \n",
       "1021              0.917317               -0.750775               1.459428   \n",
       "\n",
       "      day_incident_date  month_incident_date  year_incident_date  \\\n",
       "0             -1.393943            -0.947412                   0   \n",
       "1              0.115223             0.953085                   0   \n",
       "2              0.115223            -0.947412                   0   \n",
       "3             -1.626123             2.853582                   0   \n",
       "4              1.160031            -0.947412                   0   \n",
       "...                 ...                  ...                 ...   \n",
       "1017          -0.917630            -0.947412                   0   \n",
       "1018           0.680663             0.953085                   0   \n",
       "1019          -0.093503             0.914690                   0   \n",
       "1020           0.118865             0.953085                   0   \n",
       "1021          -0.233308            -0.947412                   0   \n",
       "\n",
       "      week_incident_date  high_week  high_hour  \n",
       "0              -1.705084          0          0  \n",
       "1               1.136723          0          0  \n",
       "2              -0.893139          1          0  \n",
       "3               1.542695          0          0  \n",
       "4              -0.487167          1          0  \n",
       "...                  ...        ...        ...  \n",
       "1017           -1.409131          0          0  \n",
       "1018            1.071228          0          0  \n",
       "1019            0.706145          1          1  \n",
       "1020            0.936124          0          0  \n",
       "1021           -0.893139          1          0  \n",
       "\n",
       "[1022 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b330998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 42, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 20, 32)       96          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 20, 32)      60          ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 20, 32)       0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 18, 32)       3072        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 18, 32)      54          ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 18, 32)       0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 16, 64)       6144        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 64)      48          ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 16, 64)       0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling1D)     (None, 7, 64)        0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 7, 64)        4096        ['block1_pool[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 7, 64)       21          ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 7, 64)        0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 7, 48)        3072        ['block1_pool[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 7, 96)        18432       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 7, 48)       21          ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 96)       21          ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 7, 48)        0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 7, 96)        0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling1d (AveragePool  (None, 7, 64)       0           ['block1_pool[0][0]']            \n",
      " ing1D)                                                                                           \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 7, 64)        4096        ['block1_pool[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 7, 64)        15360       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 7, 96)        27648       ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 7, 32)        2048        ['average_pooling1d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 7, 64)       21          ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 7, 64)       21          ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 7, 96)       21          ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 7, 32)       21          ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 7, 64)        0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 7, 64)        0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 7, 96)        0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 7, 32)        0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 7, 256)       0           ['activation_3[0][0]',           \n",
      "                                                                  'activation_5[0][0]',           \n",
      "                                                                  'activation_8[0][0]',           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 7, 64)        16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 7, 64)       21          ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 7, 64)        0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 7, 48)        12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 7, 96)        18432       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 7, 48)       21          ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 7, 96)       21          ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 7, 48)        0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 7, 96)        0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling1d_1 (AveragePo  (None, 7, 256)      0           ['mixed0[0][0]']                 \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 7, 64)        16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 7, 64)        15360       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 7, 96)        27648       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 7, 64)        16384       ['average_pooling1d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 7, 64)       21          ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 7, 64)       21          ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 7, 96)       21          ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 7, 64)       21          ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 7, 64)        0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 7, 64)        0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 7, 96)        0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 7, 64)        0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 7, 288)       0           ['activation_10[0][0]',          \n",
      "                                                                  'activation_12[0][0]',          \n",
      "                                                                  'activation_15[0][0]',          \n",
      "                                                                  'activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 7, 64)        18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 7, 64)       21          ['conv1d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 7, 64)        0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 7, 48)        13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 7, 96)        18432       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 7, 48)       21          ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 7, 96)       21          ['conv1d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 7, 48)        0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 7, 96)        0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling1d_2 (AveragePo  (None, 7, 288)      0           ['mixed1[0][0]']                 \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_17 (Conv1D)             (None, 7, 64)        18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 7, 64)        15360       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 7, 96)        27648       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 7, 64)        18432       ['average_pooling1d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 7, 64)       21          ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 7, 64)       21          ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 7, 96)       21          ['conv1d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 7, 64)       21          ['conv1d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 7, 64)        0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 7, 64)        0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 7, 96)        0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 7, 64)        0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 7, 288)       0           ['activation_17[0][0]',          \n",
      "                                                                  'activation_19[0][0]',          \n",
      "                                                                  'activation_22[0][0]',          \n",
      "                                                                  'activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 7, 64)        18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 7, 64)       21          ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 7, 64)        0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 7, 96)        18432       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 7, 96)       21          ['conv1d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 7, 96)        0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 3, 384)       331776      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 3, 96)        27648       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 3, 384)      9           ['conv1d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 3, 96)       9           ['conv1d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 3, 384)       0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 3, 96)        0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 3, 288)       0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 3, 768)       0           ['activation_24[0][0]',          \n",
      "                                                                  'activation_27[0][0]',          \n",
      "                                                                  'max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 3, 128)       98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 3, 128)      9           ['conv1d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 3, 128)       0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 3, 128)       114688      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 3, 128)      9           ['conv1d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 3, 128)       0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 3, 128)       98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv1d_34 (Conv1D)             (None, 3, 128)       16384       ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 3, 128)      9           ['conv1d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 3, 128)      9           ['conv1d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 3, 128)       0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 3, 128)       0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 3, 128)       16384       ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 3, 128)       114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 3, 128)      9           ['conv1d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 3, 128)      9           ['conv1d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 3, 128)       0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 3, 128)       0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling1d_3 (AveragePo  (None, 3, 768)      0           ['mixed3[0][0]']                 \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 3, 192)       147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 3, 192)       172032      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 3, 192)       24576       ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 3, 192)       147456      ['average_pooling1d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 3, 192)      9           ['conv1d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 3, 192)      9           ['conv1d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 3, 192)      9           ['conv1d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 3, 192)      9           ['conv1d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 3, 192)       0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 3, 192)       0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 3, 192)       0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 3, 192)       0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 3, 768)       0           ['activation_28[0][0]',          \n",
      "                                                                  'activation_31[0][0]',          \n",
      "                                                                  'activation_36[0][0]',          \n",
      "                                                                  'activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 3, 160)       122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 3, 160)      9           ['conv1d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 3, 160)       0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 3, 160)       179200      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 3, 160)      9           ['conv1d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 3, 160)       0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 3, 160)       122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 3, 160)       25600       ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 3, 160)      9           ['conv1d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_44 (BatchN  (None, 3, 160)      9           ['conv1d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 3, 160)       0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 3, 160)       0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 3, 160)       25600       ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 3, 160)       179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 3, 160)      9           ['conv1d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 3, 160)      9           ['conv1d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 3, 160)       0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 3, 160)       0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling1d_4 (AveragePo  (None, 3, 768)      0           ['mixed4[0][0]']                 \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 3, 192)       147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 3, 192)       215040      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 3, 192)       30720       ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 3, 192)       147456      ['average_pooling1d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 3, 192)      9           ['conv1d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 3, 192)      9           ['conv1d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 3, 192)      9           ['conv1d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 3, 192)      9           ['conv1d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 3, 192)       0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 3, 192)       0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 3, 192)       0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 3, 192)       0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 3, 768)       0           ['activation_38[0][0]',          \n",
      "                                                                  'activation_41[0][0]',          \n",
      "                                                                  'activation_46[0][0]',          \n",
      "                                                                  'activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 3, 160)       122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 3, 160)      9           ['conv1d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 3, 160)       0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 3, 160)       179200      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 3, 160)      9           ['conv1d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 3, 160)       0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 3, 160)       122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)             (None, 3, 160)       25600       ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 3, 160)      9           ['conv1d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 3, 160)      9           ['conv1d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 3, 160)       0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_54 (Activation)     (None, 3, 160)       0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 3, 160)       25600       ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)             (None, 3, 160)       179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 3, 160)      9           ['conv1d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 3, 160)      9           ['conv1d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 3, 160)       0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 3, 160)       0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling1d_5 (AveragePo  (None, 3, 768)      0           ['mixed5[0][0]']                 \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 3, 192)       147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 3, 192)       215040      ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_56 (Conv1D)             (None, 3, 192)       30720       ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_57 (Conv1D)             (None, 3, 192)       147456      ['average_pooling1d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 3, 192)      9           ['conv1d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 3, 192)      9           ['conv1d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 3, 192)      9           ['conv1d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 3, 192)      9           ['conv1d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 3, 192)       0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 3, 192)       0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 3, 192)       0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 3, 192)       0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 3, 768)       0           ['activation_48[0][0]',          \n",
      "                                                                  'activation_51[0][0]',          \n",
      "                                                                  'activation_56[0][0]',          \n",
      "                                                                  'activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_62 (Conv1D)             (None, 3, 192)       147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 3, 192)      9           ['conv1d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 3, 192)       0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_63 (Conv1D)             (None, 3, 192)       258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 3, 192)      9           ['conv1d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 3, 192)       0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_59 (Conv1D)             (None, 3, 192)       147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_64 (Conv1D)             (None, 3, 192)       36864       ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 3, 192)      9           ['conv1d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 3, 192)      9           ['conv1d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 3, 192)       0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 3, 192)       0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_60 (Conv1D)             (None, 3, 192)       36864       ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_65 (Conv1D)             (None, 3, 192)       258048      ['activation_64[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\miniconda3\\envs\\test\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_60 (BatchN  (None, 3, 192)      9           ['conv1d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 3, 192)      9           ['conv1d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 3, 192)       0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 3, 192)       0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling1d_6 (AveragePo  (None, 3, 768)      0           ['mixed6[0][0]']                 \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " conv1d_58 (Conv1D)             (None, 3, 192)       147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_61 (Conv1D)             (None, 3, 192)       258048      ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_66 (Conv1D)             (None, 3, 192)       36864       ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_67 (Conv1D)             (None, 3, 192)       147456      ['average_pooling1d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 3, 192)      9           ['conv1d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 3, 192)      9           ['conv1d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 3, 192)      9           ['conv1d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 3, 192)      9           ['conv1d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 3, 192)       0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 3, 192)       0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 3, 192)       0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 3, 192)       0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 3, 768)       0           ['activation_58[0][0]',          \n",
      "                                                                  'activation_61[0][0]',          \n",
      "                                                                  'activation_66[0][0]',          \n",
      "                                                                  'activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_70 (Conv1D)             (None, 3, 192)       147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 3, 192)      9           ['conv1d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 3, 192)       0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_71 (Conv1D)             (None, 3, 192)       36864       ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 3, 192)      9           ['conv1d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 3, 192)       0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_68 (Conv1D)             (None, 3, 192)       147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_72 (Conv1D)             (None, 3, 192)       258048      ['activation_71[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 3, 192)      9           ['conv1d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 3, 192)      9           ['conv1d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 3, 192)       0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 3, 192)       0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_69 (Conv1D)             (None, 1, 320)       184320      ['activation_68[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_73 (Conv1D)             (None, 1, 192)       110592      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 1, 320)      3           ['conv1d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 1, 192)      3           ['conv1d_73[0][0]']              \n",
      " ormalization)                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 1, 320)       0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 1, 192)       0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 1, 768)      0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 1, 1280)      0           ['activation_69[0][0]',          \n",
      "                                                                  'activation_73[0][0]',          \n",
      "                                                                  'max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_78 (Conv1D)             (None, 1, 448)       573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 1, 448)      3           ['conv1d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 1, 448)       0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_75 (Conv1D)             (None, 1, 384)       491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_79 (Conv1D)             (None, 1, 384)       516096      ['activation_78[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 1, 384)      3           ['conv1d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 1, 384)      3           ['conv1d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 1, 384)       0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 1, 384)       0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_76 (Conv1D)             (None, 1, 384)       147456      ['activation_75[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_77 (Conv1D)             (None, 1, 384)       442368      ['activation_75[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_80 (Conv1D)             (None, 1, 384)       147456      ['activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_81 (Conv1D)             (None, 1, 384)       442368      ['activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling1d_7 (AveragePo  (None, 1, 1280)     0           ['mixed8[0][0]']                 \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " conv1d_74 (Conv1D)             (None, 1, 320)       409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 1, 384)      3           ['conv1d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 1, 384)      3           ['conv1d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 1, 384)      3           ['conv1d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 1, 384)      3           ['conv1d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_82 (Conv1D)             (None, 1, 192)       245760      ['average_pooling1d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 1, 320)      3           ['conv1d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 1, 384)       0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 1, 384)       0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 1, 384)       0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 1, 384)       0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 1, 192)      3           ['conv1d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 1, 320)       0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 1, 768)       0           ['activation_76[0][0]',          \n",
      "                                                                  'activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1, 768)       0           ['activation_80[0][0]',          \n",
      "                                                                  'activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 1, 192)       0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mixed9 (Concatenate)           (None, 1, 2048)      0           ['activation_74[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_82[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_87 (Conv1D)             (None, 1, 448)       917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 1, 448)      3           ['conv1d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 1, 448)       0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_84 (Conv1D)             (None, 1, 384)       786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_88 (Conv1D)             (None, 1, 384)       516096      ['activation_87[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 1, 384)      3           ['conv1d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 1, 384)      3           ['conv1d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 1, 384)       0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 1, 384)       0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_85 (Conv1D)             (None, 1, 384)       147456      ['activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_86 (Conv1D)             (None, 1, 384)       442368      ['activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_89 (Conv1D)             (None, 1, 384)       147456      ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_90 (Conv1D)             (None, 1, 384)       442368      ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling1d_8 (AveragePo  (None, 1, 2048)     0           ['mixed9[0][0]']                 \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " conv1d_83 (Conv1D)             (None, 1, 320)       655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 1, 384)      3           ['conv1d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 1, 384)      3           ['conv1d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 1, 384)      3           ['conv1d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 1, 384)      3           ['conv1d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_91 (Conv1D)             (None, 1, 192)       393216      ['average_pooling1d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 1, 320)      3           ['conv1d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 1, 384)       0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 1, 384)       0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 1, 384)       0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 1, 384)       0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 1, 192)      3           ['conv1d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 1, 320)       0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 1, 768)       0           ['activation_85[0][0]',          \n",
      "                                                                  'activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1, 768)       0           ['activation_89[0][0]',          \n",
      "                                                                  'activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 1, 192)       0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 1, 2048)      0           ['activation_83[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_91[0][0]']          \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['mixed10[0][0]']                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1)            2049        ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,302,912\n",
      "Trainable params: 14,302,166\n",
      "Non-trainable params: 746\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, Reshape, GlobalAveragePooling1D,MaxPooling1D,Dense,AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def conv1d_bn(x,\n",
    "              filters,\n",
    "              kernel_size,\n",
    "              padding='same',\n",
    "              strides=1,\n",
    "              name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    bn_axis = 1\n",
    "    x = Conv1D(\n",
    "        filters, kernel_size,\n",
    "        strides=strides,\n",
    "        padding=str(padding),\n",
    "        use_bias=False,\n",
    "        name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = Activation('relu', name=name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionV3():\n",
    "    # Determine proper input shape\n",
    "    input_shape = (42,1)\n",
    "    x_input = Input(shape=input_shape)\n",
    "    channel_axis = -1\n",
    "\n",
    "    x = conv1d_bn(x_input, 32, 3, strides=2, padding='valid')\n",
    "    x = conv1d_bn(x, 32, 3, padding='valid')\n",
    "    x = conv1d_bn(x, 64, 3, padding='valid')\n",
    "    x = MaxPooling1D(3, strides=2, name=\"block1_pool\")(x)\n",
    "    # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    branch1x1 = conv1d_bn(x, 64,1,padding='same')\n",
    "\n",
    "    branch5x5 = conv1d_bn(x, 48,1,padding='same')\n",
    "    branch5x5 = conv1d_bn(branch5x5, 64, 5,padding='same')\n",
    "    branch3x3dbl = conv1d_bn(x, 64, 1,padding='same')\n",
    "    branch3x3dbl = conv1d_bn(branch3x3dbl, 96, 3,padding='same')\n",
    "    branch3x3dbl = conv1d_bn(branch3x3dbl, 96, 3,padding='same')\n",
    "    branch_pool = AveragePooling1D(3, strides=1, padding='same')(x)\n",
    "    branch_pool = conv1d_bn(branch_pool, 32, 1,padding='same')\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed0')\n",
    "\n",
    "    # mixed 1: 35 x 35 x 256\n",
    "    branch1x1 = conv1d_bn(x, 64,1,padding='same')\n",
    "    branch5x5 = conv1d_bn(x, 48, 1,padding='same')\n",
    "    branch5x5 = conv1d_bn(branch5x5, 64,5,padding='same')\n",
    "\n",
    "    branch3x3dbl = conv1d_bn(x, 64, 1,padding='same')\n",
    "    branch3x3dbl = conv1d_bn(branch3x3dbl, 96, 3,padding='same')\n",
    "    branch3x3dbl = conv1d_bn(branch3x3dbl, 96, 3,padding='same')\n",
    "\n",
    "    branch_pool = AveragePooling1D(3, strides=1, padding='same')(x)\n",
    "    branch_pool = conv1d_bn(branch_pool, 64, 1,padding='same')\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed1')\n",
    "\n",
    "    # mixed 2: 35 x 35 x 256\n",
    "    branch1x1 = conv1d_bn(x, 64, 1,padding='same')\n",
    "\n",
    "    branch5x5 = conv1d_bn(x, 48, 1,padding='same')\n",
    "    branch5x5 = conv1d_bn(branch5x5, 64, 5,padding='same')\n",
    "\n",
    "    branch3x3dbl = conv1d_bn(x, 64, 1,padding='same')\n",
    "    branch3x3dbl = conv1d_bn(branch3x3dbl, 96, 3,padding='same')\n",
    "    branch3x3dbl = conv1d_bn(branch3x3dbl, 96, 3,padding='same')\n",
    "\n",
    "    branch_pool = AveragePooling1D(3, strides=1, padding='same')(x)\n",
    "    branch_pool = conv1d_bn(branch_pool, 64, 1,padding='same')\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed2')\n",
    "\n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv1d_bn(x, 384, 3, strides=2, padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv1d_bn(x, 64, 1,padding='same')\n",
    "    branch3x3dbl = conv1d_bn(branch3x3dbl, 96, 3,padding='same')\n",
    "    branch3x3dbl = conv1d_bn(\n",
    "        branch3x3dbl, 96, 3, strides=2, padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling1D(3, strides=2)(x)\n",
    "    x = layers.concatenate(\n",
    "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n",
    "\n",
    "    # mixed 4: 17 x 17 x 768\n",
    "    branch1x1 = conv1d_bn(x, 192, 1,padding='same')\n",
    "\n",
    "    branch7x7 = conv1d_bn(x, 128, 1,padding='same')\n",
    "    branch7x7 = conv1d_bn(branch7x7, 128, 1,padding='same')\n",
    "    branch7x7 = conv1d_bn(branch7x7, 192, 7,padding='same')\n",
    "\n",
    "    branch7x7dbl = conv1d_bn(x, 128, 1,padding='same')\n",
    "    branch7x7dbl = conv1d_bn(branch7x7dbl, 128, 7,padding='same')\n",
    "    branch7x7dbl = conv1d_bn(branch7x7dbl, 128, 1,padding='same')\n",
    "    branch7x7dbl = conv1d_bn(branch7x7dbl, 128, 7,padding='same')\n",
    "    branch7x7dbl = conv1d_bn(branch7x7dbl, 192, 1,padding='same')\n",
    "\n",
    "    branch_pool = AveragePooling1D(3, strides=1, padding='same')(x)\n",
    "    branch_pool = conv1d_bn(branch_pool, 192, 1,padding='same')\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed4')\n",
    "\n",
    "    # mixed 5, 6: 17 x 17 x 768\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv1d_bn(x, 192, 1,padding='same')\n",
    "\n",
    "        branch7x7 = conv1d_bn(x, 160, 1,padding='same')\n",
    "        branch7x7 = conv1d_bn(branch7x7, 160, 1,padding='same')\n",
    "        branch7x7 = conv1d_bn(branch7x7, 192, 7,padding='same')\n",
    "\n",
    "        branch7x7dbl = conv1d_bn(x, 160, 1,padding='same')\n",
    "        branch7x7dbl = conv1d_bn(branch7x7dbl, 160, 7,padding='same')\n",
    "        branch7x7dbl = conv1d_bn(branch7x7dbl, 160, 1,padding='same')\n",
    "        branch7x7dbl = conv1d_bn(branch7x7dbl, 160, 7,padding='same')\n",
    "        branch7x7dbl = conv1d_bn(branch7x7dbl, 192, 1,padding='same')\n",
    "\n",
    "        branch_pool = AveragePooling1D(\n",
    "            3, strides=1, padding='same')(x)\n",
    "        branch_pool = conv1d_bn(branch_pool, 192, 1,padding='same')\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed' + str(5 + i))\n",
    "\n",
    "    # mixed 7: 17 x 17 x 768\n",
    "    branch1x1 = conv1d_bn(x, 192, 1,padding='same')\n",
    "\n",
    "    branch7x7 = conv1d_bn(x, 192, 1,padding='same')\n",
    "    branch7x7 = conv1d_bn(branch7x7, 192, 1,padding='same')\n",
    "    branch7x7 = conv1d_bn(branch7x7, 192, 7,padding='same')\n",
    "\n",
    "    branch7x7dbl = conv1d_bn(x, 192, 1,padding='same')\n",
    "    branch7x7dbl = conv1d_bn(branch7x7dbl, 192, 7,padding='same')\n",
    "    branch7x7dbl = conv1d_bn(branch7x7dbl, 192, 1,padding='same')\n",
    "    branch7x7dbl = conv1d_bn(branch7x7dbl, 192, 7,padding='same')\n",
    "    branch7x7dbl = conv1d_bn(branch7x7dbl, 192, 1,padding='same')\n",
    "\n",
    "    branch_pool = AveragePooling1D(3, strides=1, padding='same')(x)\n",
    "    branch_pool = conv1d_bn(branch_pool, 192, 1,padding='same')\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed7')\n",
    "\n",
    "    # mixed 8: 8 x 8 x 1280\n",
    "    branch3x3 = conv1d_bn(x, 192, 1,padding='same')\n",
    "    branch3x3 = conv1d_bn(branch3x3, 320, 3,\n",
    "                          strides=2, padding='valid')\n",
    "\n",
    "    branch7x7x3 = conv1d_bn(x, 192, 1,padding='same')\n",
    "    branch7x7x3 = conv1d_bn(branch7x7x3, 192, 1,padding='same')\n",
    "    branch7x7x3 = conv1d_bn(branch7x7x3, 192, 7,padding='same')\n",
    "    branch7x7x3 = conv1d_bn(\n",
    "        branch7x7x3, 192, 3, strides=2, padding='valid')\n",
    "\n",
    "    branch_pool = MaxPooling1D(3, strides=2)(x)\n",
    "    x = layers.concatenate(\n",
    "        [branch3x3, branch7x7x3, branch_pool], axis=channel_axis, name='mixed8')\n",
    "\n",
    "    # mixed 9: 8 x 8 x 2048\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv1d_bn(x, 320, 1,padding='same')\n",
    "\n",
    "        branch3x3 = conv1d_bn(x, 384, 1,padding='same')\n",
    "        branch3x3_1 = conv1d_bn(branch3x3, 384, 1,padding='same')\n",
    "        branch3x3_2 = conv1d_bn(branch3x3, 384, 3,padding='same')\n",
    "        branch3x3 = layers.concatenate(\n",
    "            [branch3x3_1, branch3x3_2], axis=channel_axis, name='mixed9_' + str(i))\n",
    "\n",
    "        branch3x3dbl = conv1d_bn(x, 448, 1,padding='same')\n",
    "        branch3x3dbl = conv1d_bn(branch3x3dbl, 384, 3,padding='same')\n",
    "        branch3x3dbl_1 = conv1d_bn(branch3x3dbl, 384, 1,padding='same')\n",
    "        branch3x3dbl_2 = conv1d_bn(branch3x3dbl, 384, 3,padding='same')\n",
    "        branch3x3dbl = layers.concatenate(\n",
    "            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
    "\n",
    "        branch_pool = AveragePooling1D(\n",
    "            3, strides=1, padding='same')(x)\n",
    "        branch_pool = conv1d_bn(branch_pool, 192, 1,padding='same')\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed' + str(9 + i))\n",
    "    x = GlobalAveragePooling1D(name='avg_pool')(x)\n",
    "    x = Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(x_input, x, name='inception_v3')\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2.\n",
    "    return x\n",
    "\n",
    "model = InceptionV3()\n",
    "lr=0.0001\n",
    "model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7be464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7995 - accuracy: 0.5969\n",
      "Epoch 1: val_loss improved from inf to 0.69493, saving model to Emotion_weights.hdf5\n",
      "16/16 [==============================] - 107s 5s/step - loss: 0.7995 - accuracy: 0.5969 - val_loss: 0.6949 - val_accuracy: 0.2667\n",
      "Epoch 2/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.7427\n",
      "Epoch 2: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 27s 2s/step - loss: 0.5351 - accuracy: 0.7427 - val_loss: 0.7148 - val_accuracy: 0.2667\n",
      "Epoch 3/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.7906\n",
      "Epoch 3: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.4376 - accuracy: 0.7906 - val_loss: 0.7521 - val_accuracy: 0.2667\n",
      "Epoch 4/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.8268\n",
      "Epoch 4: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 16s 1s/step - loss: 0.3920 - accuracy: 0.8268 - val_loss: 0.8085 - val_accuracy: 0.2667\n",
      "Epoch 5/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.8777\n",
      "Epoch 5: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 22s 1s/step - loss: 0.2877 - accuracy: 0.8777 - val_loss: 0.9114 - val_accuracy: 0.2667\n",
      "Epoch 6/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2075 - accuracy: 0.9256\n",
      "Epoch 6: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.2075 - accuracy: 0.9256 - val_loss: 1.0303 - val_accuracy: 0.2667\n",
      "Epoch 7/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9393\n",
      "Epoch 7: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.1685 - accuracy: 0.9393 - val_loss: 1.2608 - val_accuracy: 0.2667\n",
      "Epoch 8/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.9511\n",
      "Epoch 8: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.1316 - accuracy: 0.9511 - val_loss: 1.4083 - val_accuracy: 0.2667\n",
      "Epoch 9/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9530\n",
      "Epoch 9: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.1196 - accuracy: 0.9530 - val_loss: 1.9235 - val_accuracy: 0.2667\n",
      "Epoch 10/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.9501\n",
      "Epoch 10: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.1202 - accuracy: 0.9501 - val_loss: 2.1203 - val_accuracy: 0.2667\n",
      "Epoch 11/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9706\n",
      "Epoch 11: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.0810 - accuracy: 0.9706 - val_loss: 2.6501 - val_accuracy: 0.2667\n",
      "Epoch 12/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9912\n",
      "Epoch 12: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 3.3894 - val_accuracy: 0.2667\n",
      "Epoch 13/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9883\n",
      "Epoch 13: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.0273 - accuracy: 0.9883 - val_loss: 3.7354 - val_accuracy: 0.2667\n",
      "Epoch 14/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9765\n",
      "Epoch 14: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.0515 - accuracy: 0.9765 - val_loss: 4.2088 - val_accuracy: 0.2667\n",
      "Epoch 15/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9853\n",
      "Epoch 15: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.0401 - accuracy: 0.9853 - val_loss: 4.8267 - val_accuracy: 0.2667\n",
      "Epoch 16/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9834\n",
      "Epoch 16: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.0380 - accuracy: 0.9834 - val_loss: 5.1004 - val_accuracy: 0.2667\n",
      "Epoch 17/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9843\n",
      "Epoch 17: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.0342 - accuracy: 0.9843 - val_loss: 4.7023 - val_accuracy: 0.2758\n",
      "Epoch 18/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9863\n",
      "Epoch 18: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.0296 - accuracy: 0.9863 - val_loss: 4.1110 - val_accuracy: 0.3424\n",
      "Epoch 19/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9883\n",
      "Epoch 19: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.0353 - accuracy: 0.9883 - val_loss: 4.1608 - val_accuracy: 0.3364\n",
      "Epoch 20/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9912\n",
      "Epoch 20: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.0193 - accuracy: 0.9912 - val_loss: 4.6022 - val_accuracy: 0.4091\n",
      "Epoch 21/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9971\n",
      "Epoch 21: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 2.3651 - val_accuracy: 0.6000\n",
      "Epoch 22/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9892\n",
      "Epoch 22: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.0277 - accuracy: 0.9892 - val_loss: 1.6967 - val_accuracy: 0.6939\n",
      "Epoch 23/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9795\n",
      "Epoch 23: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.0581 - accuracy: 0.9795 - val_loss: 1.6324 - val_accuracy: 0.6364\n",
      "Epoch 24/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9912\n",
      "Epoch 24: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 4.9293 - val_accuracy: 0.3606\n",
      "Epoch 25/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9961\n",
      "Epoch 25: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.0099 - accuracy: 0.9961 - val_loss: 1.8618 - val_accuracy: 0.6758\n",
      "Epoch 26/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9990\n",
      "Epoch 26: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 2.3507 - val_accuracy: 0.6242\n",
      "Epoch 27/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9971\n",
      "Epoch 27: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 2.1011 - val_accuracy: 0.6909\n",
      "Epoch 28/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9980\n",
      "Epoch 28: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 22s 1s/step - loss: 0.0036 - accuracy: 0.9980 - val_loss: 2.0955 - val_accuracy: 0.7000\n",
      "Epoch 29/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990    \n",
      "Epoch 29: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 2.7221 - val_accuracy: 0.6091\n",
      "Epoch 30/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9912\n",
      "Epoch 30: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 2.2279 - val_accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/120\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9775\n",
      "Epoch 31: val_loss did not improve from 0.69493\n",
      "16/16 [==============================] - 21s 1s/step - loss: 0.0515 - accuracy: 0.9775 - val_loss: 2.6686 - val_accuracy: 0.5242\n",
      "Epoch 31: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 30)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=11,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=30,\n",
    "    min_lr=0.000001,\n",
    "    verbose=1,\n",
    ")\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class ConfusionMatrixCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        self.validation_data = validation_data\n",
    "        self.relist={}\n",
    "        self.acc=[]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        X_val, y_val = self.validation_data\n",
    "        y_pred = self.model.predict(X_val)\n",
    "        y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "        cm = confusion_matrix(y_val, y_pred_binary)\n",
    "        print(f\"Confusion Matrix after Epoch {epoch + 1}:\\n{cm}\")\n",
    "        print(classification_report(y_test,y_pred_binary))\n",
    "        acc = float(classification_report(y_test,y_pred_binary).split('\\n')[3].split()[2])\n",
    "        self.acc.append(acc)\n",
    "        self.relist[acc]=y_pred_binary\n",
    "\n",
    "# ... Định nghĩa mô hình ...\n",
    "\n",
    "# Tạo đối tượng callback\n",
    "confusion_matrix_callback = ConfusionMatrixCallback(validation_data=(x_test,y_test))\n",
    "\n",
    "callbacks = [early_stopping,lr_scheduler]\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = \"Emotion_weights.hdf5\", verbose = 1, save_best_only=True)\n",
    "\n",
    "history=model.fit(x=x_train,y=y_train,\n",
    "          validation_data=(x_test,y_test),\n",
    "          batch_size=64,epochs=120, callbacks=[earlystopping,checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e8495f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c93389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 137ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.49      0.60       242\n",
      "           1       0.31      0.62      0.41        88\n",
      "\n",
      "    accuracy                           0.52       330\n",
      "   macro avg       0.54      0.56      0.51       330\n",
      "weighted avg       0.66      0.52      0.55       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test,y_pred_binary))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
